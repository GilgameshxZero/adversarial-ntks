{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "079e5262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GpuDevice(id=0, task=0)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"0\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "jnp.array([0]) # So warnings don't show up later\n",
    "jax.local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0405f009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from adversarial_ntks import attacks, jsvc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5d6bcb",
   "metadata": {},
   "source": [
    "# Data generation\n",
    "\n",
    "Our data in labeled by $Y \\in \\{0, 1\\}$,\n",
    "and $X | Y \\sim \\mathcal{N}(0, \\sigma_Y \\cdot I_d)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c97af477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.63363107,  2.03409912],\n",
       "       [-0.5453523 , -0.04642183],\n",
       "       [-0.69214022,  0.33705554],\n",
       "       [-0.67382202,  0.60920451]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_normal_data(dim, s0, s1, num_samples):\n",
    "    assert num_samples % 2 == 0\n",
    "    assert s0 <= s1\n",
    "    \n",
    "    ys = np.concatenate([\n",
    "        np.zeros(shape=num_samples // 2, dtype=np.int64),\n",
    "        np.ones(shape=num_samples // 2, dtype=np.int64)\n",
    "    ])\n",
    "    \n",
    "    xs = np.concatenate([\n",
    "        np.random.normal(scale=s0, size=(num_samples // 2, dim)),\n",
    "        np.random.normal(scale=s1, size=(num_samples // 2, dim))\n",
    "    ])\n",
    "    \n",
    "    perm = np.random.permutation(num_samples)\n",
    "    xs = xs[perm]\n",
    "    ys = ys[perm]\n",
    "    \n",
    "    return xs, ys\n",
    "\n",
    "def normalize(xs: np.ndarray, norm):\n",
    "    norm_xs = xs / np.linalg.norm(xs, axis=-1, ord=norm).reshape(-1, 1)\n",
    "    return norm_xs\n",
    "\n",
    "def radial_attack(\n",
    "    xs: np.ndarray, ys: np.ndarray,\n",
    "    attack_norm, attack_eps,\n",
    "):\n",
    "    norm_xs = normalize(xs, norm=attack_norm)\n",
    "    \n",
    "    adv_xs = xs.copy()\n",
    "    adv_xs[ys == 0] += attack_eps * norm_xs[ys == 0]\n",
    "    adv_xs[ys == 1] -= attack_eps * norm_xs[ys == 1]\n",
    "    \n",
    "    return adv_xs\n",
    "\n",
    "xs, ys = generate_normal_data(dim=2, s0=0.3, s1=0.7, num_samples=4)\n",
    "radial_attack(xs=xs, ys=ys, attack_norm=2, attack_eps=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657141d5",
   "metadata": {},
   "source": [
    "## Some utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93ea72fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accs_by_cls(preds, ys):\n",
    "    return (preds[ys == 0] == 0).mean(), (preds[ys == 1] == 1).mean()\n",
    "\n",
    "def fmt_accs(accs):\n",
    "    return \"(\" + \", \".join(f\"{a:.4f}\" for a in accs) + \")\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb769a9",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e7ea436",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS = dict() # used to store experiment artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be9a70a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim = 1000\n",
    "s0, s1 = 1.0 / np.sqrt(dim), 1.3 / np.sqrt(dim)\n",
    "\n",
    "xs_train, ys_train = generate_normal_data(\n",
    "    dim=dim, s0=s0, s1=s1, num_samples=2000,\n",
    ")\n",
    "xs_test, ys_test = generate_normal_data(\n",
    "    dim=dim, s0=s0, s1=s1, num_samples=1000,\n",
    ")\n",
    "\n",
    "plt.title(\"xs_train radii\")\n",
    "plt.hist(np.linalg.norm(xs_train, ord=2, axis=-1), density=True, bins=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cd8347",
   "metadata": {},
   "source": [
    "## Kernel SVM\n",
    "\n",
    "See https://scikit-learn.org/stable/modules/svm.html#svc to check that the formulation below matches the sklearn specs.\n",
    "\n",
    "Let $(x_1, y_1), \\ldots, (x_n, y_n) \\in \\mathcal{X} \\times \\{\\pm 1\\}$ be training data.\n",
    "\n",
    "A binary kernel classifier $f_{\\alpha, b}: \\mathcal{X} \\to \\{\\pm 1\\}$ parameterized by\n",
    "$\\alpha, b \\in \\mathbb{R}^n \\times \\mathbb{R}$\n",
    "and with kernel $k: \\mathcal{X} \\times \\mathcal{X} \\to \\mathbb{R}$ acts as\n",
    "\n",
    "$$\n",
    "f_{\\alpha, b}(x) = \\mathrm{sgn} \\left( b + \\sum_{i = 1}^n \\alpha_i \\, k(x_i, x) \\right).\n",
    "$$\n",
    "\n",
    "For a SVM, $\\alpha$ and $b$ are found via empirical risk minimization on the regularized hinge loss:\n",
    "\n",
    "$$\n",
    "\\underset{\\alpha, \\,b \\,\\in\\, \\mathbb{R}^n \\times \\mathbb{R}}{\\mathrm{argmin}} \\quad\n",
    "\\sum_{i = 1}^n \\max(0, 1 - y_i f_\\alpha(x_i)) +\n",
    "\\frac{1}{2C} \\sum_{i = 1}^n \\sum_{j = 1}^n \\alpha_i \\, \\alpha_j \\, k(x_i, x_j)\n",
    "$$\n",
    "\n",
    "Here $C$ inversely controls the strength of regularization, i.e. large $C$ means no regularization.\n",
    "However note that $C$ does not automatically scale with $n$.\n",
    "\n",
    "### Notes\n",
    "For theoretical analysis, we could drop the bias term since we can incorporate it into the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f5a62ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_svm_clf(\n",
    "    clf: svm.SVC,\n",
    "    attack_eps: float,\n",
    "    pgd_step_size: float,\n",
    "    pgd_num_steps: int,\n",
    "    verbose: bool = True,\n",
    "    label: str = \"\",\n",
    "):\n",
    "    if verbose:\n",
    "        print(f\"{label}; n_support={clf.n_support_}; b={clf.intercept_}\")\n",
    "    \n",
    "    accs_train = accs_by_cls(preds=clf.predict(xs_train), ys=ys_train)\n",
    "    accs_test = accs_by_cls(preds=clf.predict(xs_test), ys=ys_test)\n",
    "    if verbose:\n",
    "        print(f\"{label}; accs_train={fmt_accs(accs_train)}; accs_test={fmt_accs(accs_test)}\")\n",
    "    \n",
    "    xs_train_arad = radial_attack(xs=xs_train, ys=ys_train, attack_norm=2, attack_eps=attack_eps)\n",
    "    xs_test_arad = radial_attack(xs=xs_test, ys=ys_test, attack_norm=2, attack_eps=attack_eps)\n",
    "    accs_train_arad = accs_by_cls(preds=clf.predict(xs_train_arad), ys=ys_train)\n",
    "    accs_test_arad = accs_by_cls(preds=clf.predict(xs_test_arad), ys=ys_test)\n",
    "    if verbose:\n",
    "        print(f\"{label}; accs_train_arad={fmt_accs(accs_train_arad)}; accs_test_arad={fmt_accs(accs_test_arad)}\")\n",
    "    \n",
    "    xs_train_pgd = attacks.pgd(\n",
    "        X=jnp.array(xs_train), Y=jnp.array(ys_train),\n",
    "        grad_func=lambda X: jsvc.grad_decision_function(clf, X),\n",
    "        eps=attack_eps, eps_norm=2,\n",
    "        step_size=pgd_step_size, step_norm=2,\n",
    "        num_steps=pgd_num_steps,\n",
    "        pixel_clip=False,\n",
    "    )\n",
    "    xs_test_pgd = attacks.pgd(\n",
    "        X=jnp.array(xs_test), Y=jnp.array(ys_test),\n",
    "        grad_func=lambda X: jsvc.grad_decision_function(clf, X),\n",
    "        eps=attack_eps, eps_norm=2,\n",
    "        step_size=pgd_step_size, step_norm=2,\n",
    "        num_steps=pgd_num_steps,\n",
    "        pixel_clip=False,\n",
    "    )\n",
    "    accs_train_pgd = accs_by_cls(preds=clf.predict(xs_train_pgd), ys=ys_train)\n",
    "    accs_test_pgd = accs_by_cls(preds=clf.predict(xs_test_pgd), ys=ys_test)\n",
    "    if verbose:\n",
    "        print(f\"{label}; accs_train_pgd={fmt_accs(accs_train_pgd)}; accs_test_pgd={fmt_accs(accs_test_pgd)}\")\n",
    "\n",
    "    return dict(\n",
    "        accs_train=accs_train,\n",
    "        accs_test=accs_test,\n",
    "        attack_eps=attack_eps,\n",
    "        accs_train_arad=accs_train_arad,\n",
    "        accs_test_arad=accs_test_arad,\n",
    "        accs_train_pgd=accs_train_pgd,\n",
    "        accs_test_pgd=accs_test_pgd,\n",
    "        xs_train_pgd=xs_train_pgd,\n",
    "        xs_test_pgd=xs_test_pgd,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee15e341",
   "metadata": {},
   "source": [
    "### Poly, deg=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8a96906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.0001; n_support=[1000 1000]; b=[-0.00021592]\n",
      "C=0.0001; accs_train=(0.9400, 0.7980); accs_test=(0.7500, 0.3040)\n",
      "C=0.0001; accs_train_arad=(0.9340, 0.7650); accs_test_arad=(0.7160, 0.2820)\n",
      "C=0.0001; accs_train_pgd=(0.0600, 0.0440); accs_test_pgd=(0.0140, 0.0100)\n",
      "C=0.01; n_support=[1000 1000]; b=[-0.02159225]\n",
      "C=0.01; accs_train=(0.9400, 0.7980); accs_test=(0.7500, 0.3040)\n",
      "C=0.01; accs_train_arad=(0.9340, 0.7650); accs_test_arad=(0.7160, 0.2820)\n",
      "C=0.01; accs_train_pgd=(0.0600, 0.0440); accs_test_pgd=(0.0140, 0.0100)\n",
      "C=1; n_support=[871 980]; b=[-0.63833934]\n",
      "C=1; accs_train=(0.9980, 0.9990); accs_test=(0.7800, 0.3140)\n",
      "C=1; accs_train_arad=(0.9980, 0.9990); accs_test_arad=(0.7540, 0.2720)\n",
      "C=1; accs_train_pgd=(0.0090, 0.0020); accs_test_pgd=(0.0080, 0.0060)\n",
      "C=100; n_support=[860 983]; b=[-0.69085282]\n",
      "C=100; accs_train=(1.0000, 1.0000); accs_test=(0.8200, 0.3120)\n",
      "C=100; accs_train_arad=(1.0000, 1.0000); accs_test_arad=(0.7640, 0.2580)\n",
      "C=100; accs_train_pgd=(0.0120, 0.0020); accs_test_pgd=(0.0120, 0.0060)\n",
      "CPU times: user 1min 15s, sys: 1.21 s, total: 1min 16s\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "RESULTS[\"svm-poly\"] = []\n",
    "for c in [1e-4, 1e-2, 1, 100]:\n",
    "    clf = svm.SVC(kernel=\"poly\", degree=2, coef0=1, C=c)\n",
    "    clf.fit(xs_train, ys_train)\n",
    "\n",
    "    res_dict = dict(clf=clf)\n",
    "    res_dict.update(\n",
    "        eval_svm_clf(\n",
    "            clf=clf,\n",
    "            label=f\"C={c}\",\n",
    "            attack_eps=0.1,\n",
    "            pgd_step_size=0.1/10,\n",
    "            pgd_num_steps=20,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    RESULTS[\"svm-poly\"].append(res_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0822791",
   "metadata": {},
   "source": [
    "### RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb6d7de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.0001; n_support=[1000 1000]; b=[0.0073058]\n",
      "C=0.0001; accs_train=(1.0000, 1.0000); accs_test=(1.0000, 1.0000)\n",
      "C=0.0001; accs_train_arad=(0.9770, 0.9910); accs_test_arad=(0.9500, 0.9840)\n",
      "C=0.0001; accs_train_pgd=(0.9770, 0.9910); accs_test_pgd=(0.9500, 0.9840)\n",
      "C=0.01; n_support=[1000 1000]; b=[0.73058003]\n",
      "C=0.01; accs_train=(1.0000, 1.0000); accs_test=(1.0000, 1.0000)\n",
      "C=0.01; accs_train_arad=(0.9770, 0.9910); accs_test_arad=(0.9500, 0.9840)\n",
      "C=0.01; accs_train_pgd=(0.9770, 0.9910); accs_test_pgd=(0.9500, 0.9840)\n",
      "C=1; n_support=[424 447]; b=[4.09425553]\n",
      "C=1; accs_train=(1.0000, 1.0000); accs_test=(1.0000, 1.0000)\n",
      "C=1; accs_train_arad=(1.0000, 1.0000); accs_test_arad=(0.9540, 0.9740)\n",
      "C=1; accs_train_pgd=(1.0000, 1.0000); accs_test_pgd=(0.9520, 0.9740)\n",
      "C=100.0; n_support=[424 447]; b=[4.09427757]\n",
      "C=100.0; accs_train=(1.0000, 1.0000); accs_test=(1.0000, 1.0000)\n",
      "C=100.0; accs_train_arad=(1.0000, 1.0000); accs_test_arad=(0.9540, 0.9740)\n",
      "C=100.0; accs_train_pgd=(1.0000, 1.0000); accs_test_pgd=(0.9520, 0.9740)\n",
      "C=10000.0; n_support=[424 447]; b=[4.09427757]\n",
      "C=10000.0; accs_train=(1.0000, 1.0000); accs_test=(1.0000, 1.0000)\n",
      "C=10000.0; accs_train_arad=(1.0000, 1.0000); accs_test_arad=(0.9540, 0.9740)\n",
      "C=10000.0; accs_train_pgd=(1.0000, 1.0000); accs_test_pgd=(0.9520, 0.9740)\n",
      "CPU times: user 1min 16s, sys: 616 ms, total: 1min 17s\n",
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "attack_eps = 0.1\n",
    "\n",
    "RESULTS[\"svm-rbf\"] = []\n",
    "for c in [1e-4, 1e-2, 1, 1e2, 1e4]:\n",
    "    clf = svm.SVC(kernel=\"rbf\", C=c)\n",
    "    clf.fit(xs_train, ys_train)\n",
    "    \n",
    "    res_dict = dict(clf=clf)\n",
    "    res_dict.update(\n",
    "        eval_svm_clf(\n",
    "            clf=clf,\n",
    "            label=f\"C={c}\",\n",
    "            attack_eps=0.1,\n",
    "            pgd_step_size=0.1/10,\n",
    "            pgd_num_steps=20,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    RESULTS[\"svm-rbf\"].append(res_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29496f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.linalg.norm(xs_test, ord=2, axis=-1), density=True, bins=50, alpha=0.5, label=\"nat\");\n",
    "plt.hist(np.linalg.norm(RESULTS[\"svm-rbf\"][0][\"xs_test_pgd\"], ord=2, axis=-1), density=True, bins=50, alpha=0.5, label=\"pgd\");\n",
    "plt.xlabel(\"radius\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44ed8e8",
   "metadata": {},
   "source": [
    "## Kernel regression\n",
    "\n",
    "Similar classifier setup to the SVM case, though we drop the intercept $b$ to simplify analysis.\n",
    "(This should be fine since we can get the intercept back via the kernel).\n",
    "\n",
    "So our classifier $f_\\alpha: \\mathcal{X} \\to \\mathbb{R}$ acts as\n",
    "\n",
    "$$\n",
    "f_{\\alpha}(x) = \\sum_{i = 1}^n \\alpha_i \\, k(x_i, x).\n",
    "$$\n",
    "\n",
    "Our loss for the regression case is just MSE, so we want to solve the problem\n",
    "\n",
    "$$\n",
    "\\underset{\\alpha \\,\\in \\, \\mathbb{R}^n}{\\mathrm{argmin}} \\quad\n",
    "\\frac{1}{n} \\sum_{i = 1}^n (f_\\alpha(x_i) - y_i)^2 + \\lambda R(\\alpha).\n",
    "$$\n",
    "\n",
    "where $R(\\alpha)$ is a regularizer and $\\lambda > 0$ controls its strength.\n",
    "\n",
    "Under ridge regression, the objective of the minimization can equivalently be written as\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\alpha)\n",
    "= \\frac{1}{n} \\|K \\alpha - Y\\|_2 + \\lambda R(\\alpha),\n",
    "$$\n",
    "\n",
    "where $K \\in \\mathbb{R}^{n \\times n}$ with $K_{ij} = k(x_i, x_j)$\n",
    "and $Y \\in \\mathbb{R}^n$ with $Y_i = y_i$.\n",
    "\n",
    "Two common forms of $R(\\alpha)$ that are amenable to analysis are\n",
    "$\\|\\alpha\\|_2^2$ or\n",
    "$\\|\\alpha\\|_H^2 = \\sum_{i = 1}^n \\sum_{j = 1}^n \\alpha_i \\, \\alpha_j \\, k(x_i, x_j)$.\n",
    "\n",
    "We study both below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639051a4",
   "metadata": {},
   "source": [
    "### Ridge regularization\n",
    "This is the case where $R(\\alpha) = \\|\\alpha\\|_2^2$.\n",
    "\n",
    "The first order condition for minimization of $\\mathcal{L}(\\cdot)$ is\n",
    "$K (K\\alpha - Y) + \\lambda n \\alpha = 0$.\n",
    "Thus when $\\lambda > 0$, there is a unique minimizer\n",
    "\n",
    "$$\n",
    "\\alpha^* = (K^2 + \\lambda n I_n)^{-1} K Y.\n",
    "$$\n",
    "\n",
    "Why is this unique? Well $K^2$ is positive semi-definite so when $\\lambda >0$ the sum $K^2 + \\lambda n I_n$ is positive definite and invertible.\n",
    "  \n",
    "In the limit as $\\lambda \\to 0$, we get $\\alpha^* \\to K^+ Y$, where $K^+$ is the [Mooreâ€“Penrose psuedo-inverse](https://en.wikipedia.org/w/index.php?title=Moore%E2%80%93Penrose_inverse&oldid=1015125066#Limit_relations) of $K$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb800056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "648eee68",
   "metadata": {},
   "source": [
    "### RKHS regularization\n",
    "This is the case where $R(\\alpha) = \\|\\alpha\\|_2^2$.\n",
    "\n",
    "The first order condition for minimization of $\\mathcal{L}(\\cdot)$ is\n",
    "$K(K\\alpha - Y) + \\lambda n K \\alpha = 0$.\n",
    "When $K$ is invertible, there is a unique minimizer\n",
    "\n",
    "$$\\alpha^* = (K + \\lambda n I_n)^{-1} Y.$$\n",
    "\n",
    "When $K$ is invertible, in the limit as $\\lambda \\to 0$ we get $\\alpha^* = K^{-1}Y$.\n",
    "\n",
    "When $K$ is not invertible, there may be multiple global minima.\n",
    "The one with smallest norm is given by\n",
    "\n",
    "$$\n",
    "\\alpha^*_{\\mathrm{min}} = (K^2 + \\lambda n K)^+ K Y.\n",
    "$$\n",
    "\n",
    "One instance where $K$ is always invertible (as long as datapoints are unique) is the RBF kernel,\n",
    "which is [strictly positive definite](https://math.stackexchange.com/q/130554/85418)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1899902c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
