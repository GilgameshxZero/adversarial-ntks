{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78e3ed38",
   "metadata": {},
   "source": [
    "## Set up libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66578c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675d5588",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from typing import Optional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "#jax.config.update(\"jax_platform_name\", \"cpu\")\n",
    "\n",
    "jnp.array([0]) # So warnings don't show up later\n",
    "jax.local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0f5882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from adversarial_ntks import attacks, jsvc, kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1cd21c",
   "metadata": {},
   "source": [
    "## Kernel regression\n",
    "\n",
    "Similar classifier setup to the SVM case, though we drop the intercept $b$ to simplify analysis.\n",
    "(This should be fine since we can get the intercept back via the kernel).\n",
    "\n",
    "So our classifier $f_\\alpha: \\mathcal{X} \\to \\mathbb{R}$ acts as\n",
    "\n",
    "$$\n",
    "f_{\\alpha}(x) = \\sum_{i = 1}^n \\alpha_i \\, k(x_i, x).\n",
    "$$\n",
    "\n",
    "Our loss for the regression case is just MSE, so we want to solve the problem\n",
    "\n",
    "$$\n",
    "\\underset{\\alpha \\,\\in \\, \\mathbb{R}^n}{\\mathrm{argmin}} \\quad\n",
    "\\frac{1}{n} \\sum_{i = 1}^n (f_\\alpha(x_i) - y_i)^2 + \\lambda R(\\alpha).\n",
    "$$\n",
    "\n",
    "where $R(\\alpha)$ is a regularizer and $\\lambda > 0$ controls its strength.\n",
    "\n",
    "Under ridge regression, the objective of the minimization can equivalently be written as\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\alpha)\n",
    "= \\frac{1}{n} \\|K \\alpha - Y\\|_2 + \\lambda R(\\alpha),\n",
    "$$\n",
    "\n",
    "where $K \\in \\mathbb{R}^{n \\times n}$ with $K_{ij} = k(x_i, x_j)$\n",
    "and $Y \\in \\mathbb{R}^n$ with $Y_i = y_i$.\n",
    "\n",
    "def binary_to_sign(ys: np.ndarray):\n",
    "Two common forms of $R(\\alpha)$ that are amenable to analysis are\n",
    "$\\|\\alpha\\|_2^2$ or\n",
    "$\\|\\alpha\\|_H^2 = \\sum_{i = 1}^n \\sum_{j = 1}^n \\alpha_i \\, \\alpha_j \\, k(x_i, x_j)$.\n",
    "We study both below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d022bd",
   "metadata": {},
   "source": [
    "### Ridge regularization\n",
    "This is the case where $R(\\alpha) = \\|\\alpha\\|_2^2$.\n",
    "\n",
    "The first order condition for minimization of $\\mathcal{L}(\\cdot)$ is\n",
    "$K (K\\alpha - Y) + \\lambda n \\alpha = 0$.\n",
    "Thus when $\\lambda > 0$, there is a unique minimizer\n",
    "\n",
    "$$\n",
    "\\alpha^* = (KK + \\lambda n I_n)^{-1} K Y = (K + \\lambda n K^+)^+ Y\n",
    "$$\n",
    "\n",
    "Why is this unique? Well $KK$ is positive semi-definite so when $\\lambda >0$ the sum $KK + \\lambda n I_n$ is positive definite and invertible.\n",
    "  \n",
    "In the limit as $\\lambda \\to 0$, we get $\\alpha^* \\to K^+ Y$, where $K^+$ is the [Mooreâ€“Penrose psuedo-inverse](https://en.wikipedia.org/w/index.php?title=Moore%E2%80%93Penrose_inverse&oldid=1015125066#Limit_relations) of $K$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb3fae8",
   "metadata": {},
   "source": [
    "### RKHS regularization\n",
    "This is the case where $R(\\alpha) = \\|\\alpha\\|_2^2$.\n",
    "\n",
    "The first order condition for minimization of $\\mathcal{L}(\\cdot)$ is\n",
    "$K(K\\alpha - Y) + \\lambda n K \\alpha = 0$.\n",
    "When $K$ is invertible, there is a unique minimizer\n",
    "\n",
    "$$\\alpha^* = (K + \\lambda n I_n)^{-1} Y.$$\n",
    "\n",
    "When $K$ is invertible, in the limit as $\\lambda \\to 0$ we get $\\alpha^* = K^{-1}Y$.\n",
    "\n",
    "When $K$ is not invertible, there may be multiple global minima.\n",
    "The one with smallest norm is given by\n",
    "\n",
    "$$\n",
    "\\alpha^*_{\\mathrm{min}} = (KK + \\lambda n K)^+ K Y = (K + \\lambda n I_n)^+ K^+ K Y.\n",
    "$$\n",
    "\n",
    "One instance where $K$ is always invertible (as long as datapoints are unique) is the RBF kernel,\n",
    "which is [strictly positive definite](https://math.stackexchange.com/q/130554/85418)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9941062f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JKernelRegressor:\n",
    "    \"\"\"Jax-based kernel regressor\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        kernel: str,\n",
    "        regularizer: str,\n",
    "        lam: float,\n",
    "        gamma: Optional[float] = None,\n",
    "        degree: Optional[int] = None,\n",
    "    ):\n",
    "        \"\"\"Small positive lam may cause numerical issues. Use lam = 0 instead.\"\"\"\n",
    "        self.kernel = kernel\n",
    "        self.gamma = gamma\n",
    "        self.degree = degree\n",
    "        \n",
    "        self.regularizer = regularizer\n",
    "        self.lam = lam\n",
    "        \n",
    "        assert self.lam >= 0\n",
    "    \n",
    "    def get_kernel_mat(self, X1: jnp.ndarray, X2: jnp.ndarray) -> jnp.ndarray:\n",
    "        \"\"\"\n",
    "        X1: shape (n1, d)\n",
    "        X1: shape (n2, d)\n",
    "        return: shape (n1, n2)\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.kernel == \"linear\":\n",
    "            return kernel.linear(SV, X)\n",
    "        elif self.kernel == \"poly\":\n",
    "            return kernel.poly(X1, X2, gamma=self.gamma, coef0=1, degree=self.degree)\n",
    "        elif self.kernel == \"rbf\":\n",
    "            return kernel.rbf(X1, X2, gamma=self.gamma)\n",
    "        \n",
    "        raise NotImplementedError\n",
    "    \n",
    "    @partial(jax.jit, static_argnums=(0,))\n",
    "    def _fit_alpha(self, K, ys):\n",
    "        \"\"\"For JITing\"\"\"\n",
    "        n = K.shape[0]\n",
    "        if self.regularizer == \"ridge\":\n",
    "            # return jnp.linalg.pinv(K + self.lam * n * self.linalg.pinv(K)) @ ys\n",
    "            if self.lam > 0:\n",
    "                return jnp.linalg.inv(K @ K + self.lam * n * jnp.eye(n)) @ K @ ys\n",
    "            return jnp.linalg.pinv(K) @ ys\n",
    "                \n",
    "        elif self.regularizer == \"rkhs\":\n",
    "            return jnp.linalg.pinv(K @ K + self.lam * n * K) @ K @ ys\n",
    "       \n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def fit(self, xs: jnp.ndarray, ys: jnp.ndarray):\n",
    "        \"\"\"\n",
    "        xs: shape (n, d)\n",
    "        ys: shape (n,)\n",
    "        \"\"\"\n",
    "        self.xs = xs.copy()\n",
    "        self.ys = ys.copy()\n",
    "        \n",
    "        self.K = self.get_kernel_mat(xs, xs)        \n",
    "        self.alpha = self._fit_alpha(K=self.K, ys=self.ys)\n",
    "    \n",
    "    def predict(self, xs: jnp.ndarray) -> jnp.ndarray:\n",
    "        \"\"\"\n",
    "        xs: shape (n, d)\n",
    "        \"\"\"\n",
    "        return self.get_kernel_mat(xs, self.xs) @ self.alpha\n",
    "    \n",
    "    def predict_thresh(self, xs: jnp.ndarray, thresh: float = 0.5) -> jnp.ndarray:\n",
    "        \"\"\"\n",
    "        xs: shape (n, d)\n",
    "        \"\"\"\n",
    "        return (self.predict(xs) > thresh).astype(jnp.int64)\n",
    "    \n",
    "def _kreg_predict_sum(kreg: JKernelRegressor, xs: jnp.ndarray):\n",
    "    return kreg.predict(xs).sum()\n",
    "\n",
    "grad_kreg_predict_sum = jax.jit(\n",
    "    jax.grad(_kreg_predict_sum, 1),\n",
    "    static_argnums=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e93cb40",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'JKernelRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b55be54300be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m def eval_kreg(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mreg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mJKernelRegressor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mattack_eps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpgd_step_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpgd_num_steps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'JKernelRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "def eval_kreg(\n",
    "    reg: JKernelRegressor,\n",
    "    attack_eps: float,\n",
    "    pgd_step_size: float,\n",
    "    pgd_num_steps: int,\n",
    "    verbose: bool = True,\n",
    "    label: str = \"\",\n",
    "):\n",
    "    accs_train = accs_by_cls(preds=reg.predict_thresh(xs_train), ys=ys_train)\n",
    "    accs_test = accs_by_cls(preds=reg.predict_thresh(xs_test), ys=ys_test)\n",
    "    if verbose:\n",
    "        print(f\"{label}; accs_train={fmt_accs(accs_train)}; accs_test={fmt_accs(accs_test)}\")\n",
    "    \n",
    "    xs_train_arad = radial_attack(xs=xs_train, ys=ys_train, attack_norm=2, attack_eps=attack_eps)\n",
    "    xs_test_arad = radial_attack(xs=xs_test, ys=ys_test, attack_norm=2, attack_eps=attack_eps)\n",
    "    accs_train_arad = accs_by_cls(preds=reg.predict_thresh(xs_train_arad), ys=ys_train)\n",
    "    accs_test_arad = accs_by_cls(preds=reg.predict_thresh(xs_test_arad), ys=ys_test)\n",
    "    if verbose:\n",
    "        print(f\"{label}; accs_train_arad={fmt_accs(accs_train_arad)}; accs_test_arad={fmt_accs(accs_test_arad)}\")\n",
    "    \n",
    "    xs_train_pgd = attacks.pgd(\n",
    "        X=jnp.array(xs_train), Y=jnp.array(ys_train),\n",
    "        grad_func=lambda X: grad_kreg_predict_sum(reg, X),\n",
    "        eps=attack_eps, eps_norm=2,\n",
    "        step_size=pgd_step_size, step_norm=2,\n",
    "        num_steps=pgd_num_steps,\n",
    "        pixel_clip=False,\n",
    "    )\n",
    "    xs_test_pgd = attacks.pgd(\n",
    "        X=jnp.array(xs_test), Y=jnp.array(ys_test),\n",
    "        grad_func=lambda X: grad_kreg_predict_sum(reg, X),\n",
    "        eps=attack_eps, eps_norm=2,\n",
    "        step_size=pgd_step_size, step_norm=2,\n",
    "        num_steps=pgd_num_steps,\n",
    "        pixel_clip=False,\n",
    "    )\n",
    "    accs_train_pgd = accs_by_cls(preds=reg.predict_thresh(xs_train_pgd), ys=ys_train)\n",
    "    accs_test_pgd = accs_by_cls(preds=reg.predict_thresh(xs_test_pgd), ys=ys_test)\n",
    "    if verbose:\n",
    "        print(f\"{label}; accs_train_pgd={fmt_accs(accs_train_pgd)}; accs_test_pgd={fmt_accs(accs_test_pgd)}\")\n",
    "\n",
    "    return dict(\n",
    "        accs_train=accs_train,\n",
    "        accs_test=accs_test,\n",
    "        attack_eps=attack_eps,\n",
    "        accs_train_arad=accs_train_arad,\n",
    "        accs_test_arad=accs_test_arad,\n",
    "        accs_train_pgd=accs_train_pgd,\n",
    "        accs_test_pgd=accs_test_pgd,\n",
    "        xs_train_pgd=xs_train_pgd,\n",
    "        xs_test_pgd=xs_test_pgd,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499a6e16",
   "metadata": {},
   "source": [
    "## RBF regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb56406",
   "metadata": {},
   "source": [
    "#### Ridge regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16eb4b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "attack_eps = 0.1\n",
    "\n",
    "RESULTS[\"reg-rbf\"] = []\n",
    "for lam in [0, 1e-9, 1e-6, 1e-3, 1]:\n",
    "    reg = JKernelRegressor(\n",
    "        kernel=\"rbf\",\n",
    "        regularizer=\"ridge\",\n",
    "        lam=lam,\n",
    "        gamma=1\n",
    "    )\n",
    "    reg.fit(xs_train, ys_train)\n",
    "    \n",
    "    res_dict = dict(reg=reg)\n",
    "    res_dict.update(\n",
    "        eval_kreg(\n",
    "            reg=reg,\n",
    "            label=f\"lam={lam}\",\n",
    "            attack_eps=0.1,\n",
    "            pgd_step_size=0.1/10,\n",
    "            pgd_num_steps=20,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    RESULTS[\"reg-rbf\"].append(res_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c45a068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(RESULTS[\"reg-rbf\"][0][\"reg\"].predict(xs_train), density=True, bins=50, alpha=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340158c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(RESULTS[\"reg-rbf\"][0][\"reg\"].predict(xs_test), density=True, bins=50, alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7318f870",
   "metadata": {},
   "source": [
    "#### RKHS regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8ee3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "attack_eps = 0.1\n",
    "\n",
    "RESULTS[\"reg-rbf\"] = []\n",
    "for lam in [0, 1e-9, 1e-6, 1e-3, 1, 1e3]:\n",
    "    reg = JKernelRegressor(\n",
    "        kernel=\"rbf\",\n",
    "        regularizer=\"rkhs\",\n",
    "        lam=lam,\n",
    "        gamma=1\n",
    "    )\n",
    "    reg.fit(xs_train, ys_train)\n",
    "    \n",
    "    res_dict = dict(reg=reg)\n",
    "    res_dict.update(\n",
    "        eval_kreg(\n",
    "            reg=reg,\n",
    "            label=f\"lam={lam}\",\n",
    "            attack_eps=0.1,\n",
    "            pgd_step_size=0.1/10,\n",
    "            pgd_num_steps=20,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    RESULTS[\"reg-rbf\"].append(res_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365a1637",
   "metadata": {},
   "source": [
    "## Poly regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f59fdfa",
   "metadata": {},
   "source": [
    "#### Ridge regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bea664f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd79f945",
   "metadata": {},
   "source": [
    "#### RKHS regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30da6f53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
