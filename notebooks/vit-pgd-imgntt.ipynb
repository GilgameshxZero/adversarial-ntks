{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "connected-trade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import functools\n",
    "import copy\n",
    "import sys\n",
    "import pickle\n",
    "import tarfile\n",
    "import operator\n",
    "import math\n",
    "import requests\n",
    "import importlib\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "import scipy\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import flax\n",
    "\n",
    "import neural_tangents as nt\n",
    "\n",
    "import vit_jax\n",
    "\n",
    "import adversarial_ntks as atk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "handled-coordinator",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES = 10\n",
    "SAMPLE_IMG_SIZE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-projector",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT = {\n",
    "    \"train\": atk.dataset.get_np_data(\n",
    "        name=\"imagenette/160px-v2\", split=\"train[:2000]\", flatten=False, image_width=64, data_dir=\".data/\"),\n",
    "    \"test\": atk.dataset.get_np_data(\n",
    "        name=\"imagenette/160px-v2\", split=\"test[:1000]\", flatten=False, image_width=64, data_dir=\".data/\"),\n",
    "    \"channels\": 3,\n",
    "    \"labels\": list(range(10)),\n",
    "    \n",
    "    \"batch_size\": 50,\n",
    "    \"pretrained_model\": \"ViT-B_16\",\n",
    "    \n",
    "    \"total_steps\": 200,\n",
    "    \"warmup_steps\": 5,\n",
    "    \"decay_type\": \"cosine\",\n",
    "    \"grad_norm_clip\": 1,\n",
    "    \n",
    "    \"accum_steps\": 10,\n",
    "    \"base_lr\": 0.1,\n",
    "    \n",
    "    \"perturb_target\": 2,\n",
    "    \"perturb_eps\": 0.02,\n",
    "    \"perturb_eps_norm\": np.inf,\n",
    "    \"perturb_num_steps\": 15,\n",
    "    \"perturb_step_size\": 0.003,\n",
    "    \"perturb_step_norm\": np.inf\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mechanical-exhibit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_show(exp):\n",
    "    exp.update({\n",
    "        \"num_classes\": len(exp[\"labels\"])\n",
    "    })\n",
    "    plt.figure(figsize=(SAMPLES * SAMPLE_IMG_SIZE, SAMPLE_IMG_SIZE))\n",
    "    atk.dataset.plot_sample_data(exp[\"train\"][0][:SAMPLES], flat=False, channels=exp[\"channels\"])\n",
    "    print(\"Labels: \", [exp[\"labels\"][a]\n",
    "        for a in exp[\"train\"][1][:SAMPLES]])\n",
    "    \n",
    "exp_show(EXPERIMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artistic-cowboy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_get_accuracy(exp, params_repl, test_imgs, test_labels):\n",
    "    good = total = 0\n",
    "    for step in tqdm.tqdm(range(len(test_imgs) // exp[\"batch_size\"])):\n",
    "        # Get the next batch.\n",
    "        batch = test_imgs[step * exp[\"batch_size\"]:(step + 1) * exp[\"batch_size\"]]\n",
    "        batch_labels = test_labels[step * exp[\"batch_size\"]:(step + 1) * exp[\"batch_size\"]]\n",
    "        predictions = exp[\"vit_apply_repl\"](\n",
    "            params_repl, np.array([batch]))\n",
    "\n",
    "        # Predictions are likely constant on the pretrained initialization.\n",
    "        is_same = predictions.argmax(axis=-1) == np.array([batch_labels])\n",
    "        good += is_same.sum()\n",
    "        total += len(is_same.flatten())\n",
    "    return good / total\n",
    "\n",
    "def exp_show_accuracy(exp, params_repl, test_imgs, test_labels):\n",
    "    batch = test_imgs[:exp[\"batch_size\"]]\n",
    "    batch_labels = test_labels[:exp[\"batch_size\"]]\n",
    "    batch_predictions = exp[\"vit_apply_repl\"](params_repl, np.array([batch]))\n",
    "    print(\"Correct labels:\", [exp[\"labels\"][a]\n",
    "        for a in batch_labels[:SAMPLES]])\n",
    "    plt.figure(figsize=(SAMPLES * SAMPLE_IMG_SIZE, SAMPLE_IMG_SIZE))\n",
    "    atk.dataset.plot_sample_data(batch[:SAMPLES], flat=False, channels=exp[\"channels\"])\n",
    "    print(\"Predicted labels:\", [exp[\"labels\"][a]\n",
    "        for a in batch_predictions[0][:SAMPLES].argmax(axis=-1)])\n",
    "    \n",
    "def exp_show_rob_accuracy(exp, params_repl, test_imgs, test_labels, test_perturbed):\n",
    "    exp_show_accuracy(exp, params_repl, test_imgs, test_labels)\n",
    "    perturbed_batch = test_perturbed[:exp[\"batch_size\"]]\n",
    "    perturbed_predictions = exp[\"vit_apply_repl\"](\n",
    "        params_repl, np.array([perturbed_batch]))\n",
    "    plt.figure(figsize=(SAMPLES * SAMPLE_IMG_SIZE, SAMPLE_IMG_SIZE))\n",
    "    atk.dataset.plot_sample_data(perturbed_batch[:SAMPLES], flat=False, channels=exp[\"channels\"])\n",
    "    print(\"Perturbed labels:\", [exp[\"labels\"][a]\n",
    "        for a in perturbed_predictions[0][:SAMPLES].argmax(axis=-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-sierra",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_test_pretrained(exp):\n",
    "    exp.update({\n",
    "    \"model\": vit_jax.models.KNOWN_MODELS[exp[\"pretrained_model\"]] \\\n",
    "        .partial(num_classes=exp[\"num_classes\"])\n",
    "    })\n",
    "    exp.update({\n",
    "        \"params\": vit_jax.checkpoint.load_pretrained(\n",
    "            pretrained_path=\".models/\" + exp[\"pretrained_model\"] + \".npz\",\n",
    "            init_params=exp[\"model\"].init_by_shape(\n",
    "                jax.random.PRNGKey(0),\n",
    "                [((exp[\"batch_size\"], *exp[\"train\"][0][0].shape), \"float32\")])[1],\n",
    "            model_config=vit_jax.models.CONFIGS[exp[\"pretrained_model\"]],\n",
    "            logger=vit_jax.logging.setup_logger('.logs/'))\n",
    "    })\n",
    "    exp.update({\n",
    "        \"params_repl\": flax.jax_utils.replicate(exp[\"params\"]),\n",
    "        \"vit_apply_repl\": jax.pmap(exp[\"model\"].call)\n",
    "    })\n",
    "    exp.update({\n",
    "        \"accuracies\": {\n",
    "            \"test_pretrained\": float(exp_get_accuracy(\n",
    "                exp, exp[\"params_repl\"], *exp[\"test\"]))\n",
    "        }\n",
    "    })\n",
    "    \n",
    "exp_test_pretrained(EXPERIMENT)\n",
    "exp_show_accuracy(EXPERIMENT, EXPERIMENT[\"params_repl\"], *EXPERIMENT[\"test\"])\n",
    "print(\"CIFAR10 accuracies:\", EXPERIMENT[\"accuracies\"])  # Should be about 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-protein",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_fine_tune(exp):\n",
    "    # Fine-tune the final layer\n",
    "    exp.update({\n",
    "        \"update_fn_repl\": vit_jax.train.make_update_fn(\n",
    "            exp[\"model\"].call, exp[\"accum_steps\"]),\n",
    "        \"opt\": vit_jax.momentum_clip.Optimizer(grad_norm_clip=exp[\"grad_norm_clip\"]) \\\n",
    "            .create(exp[\"params\"])\n",
    "    })\n",
    "    exp.update({\n",
    "        \"opt_repl\": flax.jax_utils.replicate(exp[\"opt\"]),\n",
    "        \"lr_fn\": vit_jax.hyper.create_learning_rate_schedule(\n",
    "            exp[\"total_steps\"], exp[\"base_lr\"],\n",
    "            exp[\"decay_type\"], exp[\"warmup_steps\"])\n",
    "    })\n",
    "    exp.update({\n",
    "        \"lr_iter\": vit_jax.hyper.lr_prefetch_iter(exp[\"lr_fn\"], 0, exp[\"total_steps\"]),\n",
    "        \"update_rngs\": jax.random.split(jax.random.PRNGKey(0), jax.local_device_count())\n",
    "    })\n",
    "\n",
    "    for step, lr_repl in zip(\n",
    "        tqdm.tqdm(range(exp[\"total_steps\"])),\n",
    "        exp[\"lr_iter\"]):\n",
    "        step_mod = step % (len(exp[\"train\"][0]) // exp[\"batch_size\"])\n",
    "        batch = exp[\"train\"][0][step_mod * exp[\"batch_size\"]:(step_mod + 1) * exp[\"batch_size\"]]\n",
    "        batch_labels = exp[\"train\"][1][step_mod * exp[\"batch_size\"]:(step_mod + 1) * exp[\"batch_size\"]]\n",
    "        exp[\"opt_repl\"], _, exp[\"update_rngs\"] = exp[\"update_fn_repl\"](\n",
    "            exp[\"opt_repl\"], lr_repl, {\n",
    "                \"image\": np.array([batch]),\n",
    "                \"label\": np.array([\n",
    "                    [[1 if a == label else 0\n",
    "                        for a in range(exp[\"num_classes\"])]\n",
    "                        for label in batch_labels]\n",
    "                ])\n",
    "            }, exp[\"update_rngs\"])\n",
    "    exp.update({\n",
    "        \"opt_repl_target\": exp[\"opt_repl\"].target\n",
    "    })\n",
    "    exp[\"accuracies\"].update({\n",
    "        \"test_fine_tuned\": float(exp_get_accuracy(\n",
    "            exp, exp[\"opt_repl_target\"], *exp[\"test\"]))\n",
    "    })\n",
    "    \n",
    "exp_fine_tune(EXPERIMENT)\n",
    "exp_show_accuracy(EXPERIMENT, EXPERIMENT[\"opt_repl_target\"], *EXPERIMENT[\"test\"])\n",
    "print(\"CIFAR10 accuracies:\", EXPERIMENT[\"accuracies\"])  # Should be over 0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-commander",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_pgd(exp):\n",
    "    exp[\"perturbed\"] = []\n",
    "    for step in tqdm.tqdm(range(len(exp[\"test\"][0]) // exp[\"batch_size\"])):\n",
    "        # Get the next batch.\n",
    "        batch = exp[\"test\"][0][step * exp[\"batch_size\"]:(step + 1) * exp[\"batch_size\"]]\n",
    "        batch_labels = exp[\"test\"][1][step * exp[\"batch_size\"]:(step + 1) * exp[\"batch_size\"]]\n",
    "        perturbed_batch = atk.attacks.pgd(\n",
    "            batch.reshape((exp[\"batch_size\"], -1)),\n",
    "            batch_labels == exp[\"perturb_target\"],  # Binary w.r.t. airplanes.\n",
    "            lambda X: jnp.sum(jnp.array([\n",
    "                jax.grad(lambda XX: exp[\"vit_apply_repl\"](\n",
    "                    exp[\"opt_repl_target\"],\n",
    "                    jnp.array([XX.reshape(batch.shape)]))[0][a][exp[\"perturb_target\"]]\n",
    "                )(X) for a in range(exp[\"batch_size\"])]), axis=0),\n",
    "            exp[\"perturb_eps\"], exp[\"perturb_eps_norm\"], exp[\"perturb_num_steps\"],\n",
    "            exp[\"perturb_step_size\"], exp[\"perturb_step_norm\"]).reshape(batch.shape)\n",
    "        exp[\"perturbed\"].append(perturbed_batch)\n",
    "    exp[\"perturbed\"] = np.vstack(exp[\"perturbed\"])\n",
    "\n",
    "    exp[\"accuracies\"].update({\n",
    "        \"test_perturbed\": float(exp_get_accuracy(\n",
    "            exp, exp[\"opt_repl_target\"],\n",
    "            exp[\"perturbed\"], exp[\"test\"][1]))\n",
    "    })\n",
    "    \n",
    "exp_pgd(EXPERIMENT)\n",
    "exp_show_rob_accuracy(EXPERIMENT,\n",
    "    CIFAR10_TEST[\"opt_repl_target\"], *EXPERIMENT[\"test\"], EXPERIMENT[\"perturbed\"])\n",
    "print(\"CIFAR10 accuracies:\", EXPERIMENT[\"accuracies\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-parking",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
