{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('.venv': venv)"
  },
  "interpreter": {
   "hash": "55eb1c5351bbe7b168d92408519a4b79c3fa0a393701d589861ea98309fe7e7d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf .models\n",
    "!mkdir .models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q -O .models/cifar_nat.pt \"https://www.dropbox.com/s/yhpp4yws7sgi6lj/cifar_nat.pt?dl=1\"\n",
    "!wget -q -O .models/cifar_linf_8.pt \"https://www.dropbox.com/s/c9qlt1lbdnu9tlo/cifar_linf_8.pt?dl=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "c:\\users\\0\\main\\active\\monochrome\\adversarial-ntks\\robustness\\robustness\\train.py:24: UserWarning: Could not import amp.\n  warnings.warn('Could not import amp.')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import functools\n",
    "import copy\n",
    "import sys\n",
    "import pickle\n",
    "import tarfile\n",
    "import operator\n",
    "import math\n",
    "import requests\n",
    "import importlib\n",
    "os.environ[\"NOTEBOOK_MODE\"] = \"1\"\n",
    "\n",
    "import tqdm\n",
    "import cox\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "import scipy\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import torch\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import flax\n",
    "import neural_tangents as nt\n",
    "import art\n",
    "import robustness\n",
    "from robustness import model_utils, datasets, train, defaults\n",
    "\n",
    "import vit_jax\n",
    "\n",
    "import adversarial_ntks as atk\n",
    "from adversarial_ntks import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR10 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ples [01:00, 736.42 examples/s]\u001b[A\n",
      "Generating train examples...: 42100 examples [01:00, 766.56 examples/s]\u001b[A\n",
      "Generating train examples...: 42183 examples [01:00, 784.91 examples/s]\u001b[A\n",
      "Generating train examples...: 42262 examples [01:00, 758.28 examples/s]\u001b[A\n",
      "Generating train examples...: 42339 examples [01:00, 724.52 examples/s]\u001b[A\n",
      "Generating train examples...: 42412 examples [01:00, 688.81 examples/s]\u001b[A\n",
      "Generating train examples...: 42493 examples [01:00, 721.89 examples/s]\u001b[A\n",
      "Generating train examples...: 42567 examples [01:01, 724.58 examples/s]\u001b[A\n",
      "Generating train examples...: 42641 examples [01:01, 728.34 examples/s]\u001b[A\n",
      "Generating train examples...: 42716 examples [01:01, 734.25 examples/s]\u001b[A\n",
      "Generating train examples...: 42799 examples [01:01, 761.94 examples/s]\u001b[A\n",
      "Generating train examples...: 42876 examples [01:01, 742.18 examples/s]\u001b[A\n",
      "Generating train examples...: 42951 examples [01:01, 739.23 examples/s]\u001b[A\n",
      "Generating train examples...: 43026 examples [01:01, 733.40 examples/s]\u001b[A\n",
      "Generating train examples...: 43109 examples [01:01, 760.23 examples/s]\u001b[A\n",
      "Generating train examples...: 43186 examples [01:01, 757.69 examples/s]\u001b[A\n",
      "Generating train examples...: 43262 examples [01:01, 746.87 examples/s]\u001b[A\n",
      "Generating train examples...: 43341 examples [01:02, 754.09 examples/s]\u001b[A\n",
      "Generating train examples...: 43422 examples [01:02, 769.08 examples/s]\u001b[A\n",
      "Generating train examples...: 43499 examples [01:02, 728.53 examples/s]\u001b[A\n",
      "Generating train examples...: 43573 examples [01:02, 727.58 examples/s]\u001b[A\n",
      "Generating train examples...: 43647 examples [01:02, 727.11 examples/s]\u001b[A\n",
      "Generating train examples...: 43725 examples [01:02, 740.93 examples/s]\u001b[A\n",
      "Generating train examples...: 43806 examples [01:02, 760.32 examples/s]\u001b[A\n",
      "Generating train examples...: 43883 examples [01:02, 759.98 examples/s]\u001b[A\n",
      "Generating train examples...: 43960 examples [01:02, 732.96 examples/s]\u001b[A\n",
      "Generating train examples...: 44034 examples [01:03, 732.59 examples/s]\u001b[A\n",
      "Generating train examples...: 44108 examples [01:03, 664.00 examples/s]\u001b[A\n",
      "Generating train examples...: 44176 examples [01:03, 652.18 examples/s]\u001b[A\n",
      "Generating train examples...: 44243 examples [01:03, 630.98 examples/s]\u001b[A\n",
      "Generating train examples...: 44318 examples [01:03, 661.85 examples/s]\u001b[A\n",
      "Generating train examples...: 44387 examples [01:03, 668.33 examples/s]\u001b[A\n",
      "Generating train examples...: 44465 examples [01:03, 700.03 examples/s]\u001b[A\n",
      "Generating train examples...: 44548 examples [01:03, 736.78 examples/s]\u001b[A\n",
      "Generating train examples...: 44630 examples [01:03, 760.47 examples/s]\u001b[A\n",
      "Generating train examples...: 44707 examples [01:03, 751.85 examples/s]\u001b[A\n",
      "Generating train examples...: 44783 examples [01:04, 745.38 examples/s]\u001b[A\n",
      "Generating train examples...: 44863 examples [01:04, 753.89 examples/s]\u001b[A\n",
      "Generating train examples...: 44939 examples [01:04, 748.65 examples/s]\u001b[A\n",
      "Generating train examples...: 45015 examples [01:04, 750.22 examples/s]\u001b[A\n",
      "Generating train examples...: 45096 examples [01:04, 766.75 examples/s]\u001b[A\n",
      "Generating train examples...: 45175 examples [01:04, 771.85 examples/s]\u001b[A\n",
      "Generating train examples...: 45253 examples [01:04, 756.63 examples/s]\u001b[A\n",
      "Generating train examples...: 45329 examples [01:04, 757.25 examples/s]\u001b[A\n",
      "Generating train examples...: 45405 examples [01:04, 753.56 examples/s]\u001b[A\n",
      "Generating train examples...: 45485 examples [01:04, 766.87 examples/s]\u001b[A\n",
      "Generating train examples...: 45562 examples [01:05, 720.08 examples/s]\u001b[A\n",
      "Generating train examples...: 45636 examples [01:05, 723.78 examples/s]\u001b[A\n",
      "Generating train examples...: 45712 examples [01:05, 732.83 examples/s]\u001b[A\n",
      "Generating train examples...: 45786 examples [01:05, 731.05 examples/s]\u001b[A\n",
      "Generating train examples...: 45864 examples [01:05, 745.06 examples/s]\u001b[A\n",
      "Generating train examples...: 45939 examples [01:05, 736.27 examples/s]\u001b[A\n",
      "Generating train examples...: 46021 examples [01:05, 754.59 examples/s]\u001b[A\n",
      "Generating train examples...: 46097 examples [01:05, 747.59 examples/s]\u001b[A\n",
      "Generating train examples...: 46172 examples [01:05, 743.67 examples/s]\u001b[A\n",
      "Generating train examples...: 46251 examples [01:06, 755.73 examples/s]\u001b[A\n",
      "Generating train examples...: 46327 examples [01:06, 748.62 examples/s]\u001b[A\n",
      "Generating train examples...: 46402 examples [01:06, 737.16 examples/s]\u001b[A\n",
      "Generating train examples...: 46478 examples [01:06, 740.31 examples/s]\u001b[A\n",
      "Generating train examples...: 46554 examples [01:06, 744.51 examples/s]\u001b[A\n",
      "Generating train examples...: 46633 examples [01:06, 757.60 examples/s]\u001b[A\n",
      "Generating train examples...: 46709 examples [01:06, 747.24 examples/s]\u001b[A\n",
      "Generating train examples...: 46784 examples [01:06, 607.34 examples/s]\u001b[A\n",
      "Generating train examples...: 46849 examples [01:06, 552.12 examples/s]\u001b[A\n",
      "Generating train examples...: 46908 examples [01:07, 546.55 examples/s]\u001b[A\n",
      "Generating train examples...: 46966 examples [01:07, 551.21 examples/s]\u001b[A\n",
      "Generating train examples...: 47023 examples [01:07, 532.00 examples/s]\u001b[A\n",
      "Generating train examples...: 47078 examples [01:07, 480.23 examples/s]\u001b[A\n",
      "Generating train examples...: 47157 examples [01:07, 558.37 examples/s]\u001b[A\n",
      "Generating train examples...: 47231 examples [01:07, 605.15 examples/s]\u001b[A\n",
      "Generating train examples...: 47311 examples [01:07, 657.20 examples/s]\u001b[A\n",
      "Generating train examples...: 47394 examples [01:07, 704.37 examples/s]\u001b[A\n",
      "Generating train examples...: 47467 examples [01:07, 708.96 examples/s]\u001b[A\n",
      "Generating train examples...: 47546 examples [01:08, 732.19 examples/s]\u001b[A\n",
      "Generating train examples...: 47624 examples [01:08, 744.22 examples/s]\u001b[A\n",
      "Generating train examples...: 47701 examples [01:08, 751.62 examples/s]\u001b[A\n",
      "Generating train examples...: 47777 examples [01:08, 745.21 examples/s]\u001b[A\n",
      "Generating train examples...: 47857 examples [01:08, 759.89 examples/s]\u001b[A\n",
      "Generating train examples...: 47943 examples [01:08, 788.14 examples/s]\u001b[A\n",
      "Generating train examples...: 48023 examples [01:08, 726.55 examples/s]\u001b[A\n",
      "Generating train examples...: 48097 examples [01:08, 640.61 examples/s]\u001b[A\n",
      "Generating train examples...: 48164 examples [01:09, 505.92 examples/s]\u001b[A\n",
      "Generating train examples...: 48221 examples [01:09, 494.90 examples/s]\u001b[A\n",
      "Generating train examples...: 48283 examples [01:09, 523.88 examples/s]\u001b[A\n",
      "Generating train examples...: 48339 examples [01:09, 505.54 examples/s]\u001b[A\n",
      "Generating train examples...: 48397 examples [01:09, 521.75 examples/s]\u001b[A\n",
      "Generating train examples...: 48461 examples [01:09, 551.60 examples/s]\u001b[A\n",
      "Generating train examples...: 48521 examples [01:09, 564.55 examples/s]\u001b[A\n",
      "Generating train examples...: 48583 examples [01:09, 580.03 examples/s]\u001b[A\n",
      "Generating train examples...: 48643 examples [01:09, 561.32 examples/s]\u001b[A\n",
      "Generating train examples...: 48705 examples [01:10, 574.62 examples/s]\u001b[A\n",
      "Generating train examples...: 48768 examples [01:10, 589.27 examples/s]\u001b[A\n",
      "Generating train examples...: 48828 examples [01:10, 590.46 examples/s]\u001b[A\n",
      "Generating train examples...: 48889 examples [01:10, 595.96 examples/s]\u001b[A\n",
      "Generating train examples...: 48949 examples [01:10, 593.67 examples/s]\u001b[A\n",
      "Generating train examples...: 49009 examples [01:10, 525.23 examples/s]\u001b[A\n",
      "Generating train examples...: 49064 examples [01:10, 495.71 examples/s]\u001b[A\n",
      "Generating train examples...: 49120 examples [01:10, 511.38 examples/s]\u001b[A\n",
      "Generating train examples...: 49188 examples [01:10, 555.34 examples/s]\u001b[A\n",
      "Generating train examples...: 49264 examples [01:11, 608.47 examples/s]\u001b[A\n",
      "Generating train examples...: 49337 examples [01:11, 642.99 examples/s]\u001b[A\n",
      "Generating train examples...: 49409 examples [01:11, 662.51 examples/s]\u001b[A\n",
      "Generating train examples...: 49486 examples [01:11, 692.59 examples/s]\u001b[A\n",
      "Generating train examples...: 49557 examples [01:11, 697.19 examples/s]\u001b[A\n",
      "Generating train examples...: 49628 examples [01:11, 606.16 examples/s]\u001b[A\n",
      "Generating train examples...: 49694 examples [01:11, 618.72 examples/s]\u001b[A\n",
      "Generating train examples...: 49758 examples [01:11, 622.77 examples/s]\u001b[A\n",
      "Generating train examples...: 49830 examples [01:11, 649.85 examples/s]\u001b[A\n",
      "Generating train examples...: 49898 examples [01:11, 658.48 examples/s]\u001b[A\n",
      "Generating train examples...: 49970 examples [01:12, 674.63 examples/s]\u001b[A\n",
      "                                                                       \u001b[A\n",
      "Shuffling cifar10-train.tfrecord...:   0%|          | 0/50000 [00:00<?, ? examples/s]\u001b[A\n",
      "Shuffling cifar10-train.tfrecord...:   2%|▏         | 1192/50000 [00:00<00:04, 11895.71 examples/s]\u001b[A\n",
      "Shuffling cifar10-train.tfrecord...:  11%|█         | 5349/50000 [00:00<00:01, 29219.05 examples/s]\u001b[A\n",
      "Shuffling cifar10-train.tfrecord...:  19%|█▉        | 9574/50000 [00:00<00:01, 35122.47 examples/s]\u001b[A\n",
      "Shuffling cifar10-train.tfrecord...:  28%|██▊       | 14163/50000 [00:00<00:00, 39221.57 examples/s]\u001b[A\n",
      "Shuffling cifar10-train.tfrecord...:  37%|███▋      | 18709/50000 [00:00<00:00, 41412.65 examples/s]\u001b[A\n",
      "Shuffling cifar10-train.tfrecord...:  46%|████▌     | 22850/50000 [00:00<00:00, 39976.50 examples/s]\u001b[A\n",
      "Shuffling cifar10-train.tfrecord...:  54%|█████▎    | 26856/50000 [00:00<00:00, 39933.21 examples/s]\u001b[A\n",
      "Shuffling cifar10-train.tfrecord...:  62%|██████▏   | 30917/50000 [00:00<00:00, 40142.61 examples/s]\u001b[A\n",
      "Shuffling cifar10-train.tfrecord...:  71%|███████   | 35536/50000 [00:00<00:00, 41918.11 examples/s]\u001b[A\n",
      "Shuffling cifar10-train.tfrecord...:  80%|████████  | 40022/50000 [00:01<00:00, 42751.09 examples/s]\u001b[A\n",
      "Shuffling cifar10-train.tfrecord...:  89%|████████▉ | 44417/50000 [00:01<00:00, 43068.26 examples/s]\u001b[A\n",
      "Shuffling cifar10-train.tfrecord...:  97%|█████████▋| 48727/50000 [00:01<00:00, 42832.92 examples/s]\u001b[A\n",
      "Generating splits...:  50%|█████     | 1/2 [01:13<01:13, 73.45s/ splits]\n",
      "Generating test examples...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "Generating test examples...: 45 examples [00:00, 441.93 examples/s]\u001b[A\n",
      "Generating test examples...: 121 examples [00:00, 623.91 examples/s]\u001b[A\n",
      "Generating test examples...: 193 examples [00:00, 664.47 examples/s]\u001b[A\n",
      "Generating test examples...: 272 examples [00:00, 710.80 examples/s]\u001b[A\n",
      "Generating test examples...: 348 examples [00:00, 728.41 examples/s]\u001b[A\n",
      "Generating test examples...: 421 examples [00:00, 707.37 examples/s]\u001b[A\n",
      "Generating test examples...: 492 examples [00:00, 703.89 examples/s]\u001b[A\n",
      "Generating test examples...: 566 examples [00:00, 713.83 examples/s]\u001b[A\n",
      "Generating test examples...: 638 examples [00:00, 646.37 examples/s]\u001b[A\n",
      "Generating test examples...: 713 examples [00:01, 675.19 examples/s]\u001b[A\n",
      "Generating test examples...: 788 examples [00:01, 696.52 examples/s]\u001b[A\n",
      "Generating test examples...: 859 examples [00:01, 694.09 examples/s]\u001b[A\n",
      "Generating test examples...: 929 examples [00:01, 657.32 examples/s]\u001b[A\n",
      "Generating test examples...: 996 examples [00:01, 642.73 examples/s]\u001b[A\n",
      "Generating test examples...: 1072 examples [00:01, 674.81 examples/s]\u001b[A\n",
      "Generating test examples...: 1151 examples [00:01, 706.65 examples/s]\u001b[A\n",
      "Generating test examples...: 1234 examples [00:01, 740.93 examples/s]\u001b[A\n",
      "Generating test examples...: 1309 examples [00:01, 732.40 examples/s]\u001b[A\n",
      "Generating test examples...: 1383 examples [00:01, 725.93 examples/s]\u001b[A\n",
      "Generating test examples...: 1463 examples [00:02, 743.64 examples/s]\u001b[A\n",
      "Generating test examples...: 1542 examples [00:02, 752.94 examples/s]\u001b[A\n",
      "Generating test examples...: 1618 examples [00:02, 752.99 examples/s]\u001b[A\n",
      "Generating test examples...: 1694 examples [00:02, 745.44 examples/s]\u001b[A\n",
      "Generating test examples...: 1769 examples [00:02, 719.32 examples/s]\u001b[A\n",
      "Generating test examples...: 1844 examples [00:02, 727.76 examples/s]\u001b[A\n",
      "Generating test examples...: 1918 examples [00:02, 730.05 examples/s]\u001b[A\n",
      "Generating test examples...: 1992 examples [00:02, 668.38 examples/s]\u001b[A\n",
      "Generating test examples...: 2060 examples [00:02, 659.42 examples/s]\u001b[A\n",
      "Generating test examples...: 2133 examples [00:03, 678.06 examples/s]\u001b[A\n",
      "Generating test examples...: 2204 examples [00:03, 686.82 examples/s]\u001b[A\n",
      "Generating test examples...: 2274 examples [00:03, 674.10 examples/s]\u001b[A\n",
      "Generating test examples...: 2342 examples [00:03, 647.51 examples/s]\u001b[A\n",
      "Generating test examples...: 2408 examples [00:03, 627.01 examples/s]\u001b[A\n",
      "Generating test examples...: 2472 examples [00:03, 611.85 examples/s]\u001b[A\n",
      "Generating test examples...: 2541 examples [00:03, 633.62 examples/s]\u001b[A\n",
      "Generating test examples...: 2610 examples [00:03, 648.19 examples/s]\u001b[A\n",
      "Generating test examples...: 2680 examples [00:03, 659.89 examples/s]\u001b[A\n",
      "Generating test examples...: 2754 examples [00:04, 681.94 examples/s]\u001b[A\n",
      "Generating test examples...: 2833 examples [00:04, 708.36 examples/s]\u001b[A\n",
      "Generating test examples...: 2911 examples [00:04, 727.61 examples/s]\u001b[A\n",
      "Generating test examples...: 2984 examples [00:04, 722.77 examples/s]\u001b[A\n",
      "Generating test examples...: 3058 examples [00:04, 726.86 examples/s]\u001b[A\n",
      "Generating test examples...: 3131 examples [00:04, 723.22 examples/s]\u001b[A\n",
      "Generating test examples...: 3204 examples [00:04, 707.98 examples/s]\u001b[A\n",
      "Generating test examples...: 3280 examples [00:04, 721.61 examples/s]\u001b[A\n",
      "Generating test examples...: 3359 examples [00:04, 739.52 examples/s]\u001b[A\n",
      "Generating test examples...: 3434 examples [00:04, 697.87 examples/s]\u001b[A\n",
      "Generating test examples...: 3512 examples [00:05, 719.85 examples/s]\u001b[A\n",
      "Generating test examples...: 3585 examples [00:05, 721.98 examples/s]\u001b[A\n",
      "Generating test examples...: 3658 examples [00:05, 719.08 examples/s]\u001b[A\n",
      "Generating test examples...: 3731 examples [00:05, 720.17 examples/s]\u001b[A\n",
      "Generating test examples...: 3806 examples [00:05, 728.57 examples/s]\u001b[A\n",
      "Generating test examples...: 3880 examples [00:05, 730.36 examples/s]\u001b[A\n",
      "Generating test examples...: 3954 examples [00:05, 709.63 examples/s]\u001b[A\n",
      "Generating test examples...: 4026 examples [00:05, 708.41 examples/s]\u001b[A\n",
      "Generating test examples...: 4101 examples [00:05, 720.56 examples/s]\u001b[A\n",
      "Generating test examples...: 4181 examples [00:05, 743.28 examples/s]\u001b[A\n",
      "Generating test examples...: 4256 examples [00:06, 656.78 examples/s]\u001b[A\n",
      "Generating test examples...: 4334 examples [00:06, 690.09 examples/s]\u001b[A\n",
      "Generating test examples...: 4406 examples [00:06, 697.41 examples/s]\u001b[A\n",
      "Generating test examples...: 4483 examples [00:06, 716.62 examples/s]\u001b[A\n",
      "Generating test examples...: 4556 examples [00:06, 714.54 examples/s]\u001b[A\n",
      "Generating test examples...: 4629 examples [00:06, 715.83 examples/s]\u001b[A\n",
      "Generating test examples...: 4702 examples [00:06, 719.16 examples/s]\u001b[A\n",
      "Generating test examples...: 4775 examples [00:06, 693.83 examples/s]\u001b[A\n",
      "Generating test examples...: 4845 examples [00:06, 677.93 examples/s]\u001b[A\n",
      "Generating test examples...: 4918 examples [00:07, 688.86 examples/s]\u001b[A\n",
      "Generating test examples...: 4992 examples [00:07, 703.19 examples/s]\u001b[A\n",
      "Generating test examples...: 5066 examples [00:07, 710.21 examples/s]\u001b[A\n",
      "Generating test examples...: 5140 examples [00:07, 717.75 examples/s]\u001b[A\n",
      "Generating test examples...: 5212 examples [00:07, 714.92 examples/s]\u001b[A\n",
      "Generating test examples...: 5289 examples [00:07, 728.65 examples/s]\u001b[A\n",
      "Generating test examples...: 5365 examples [00:07, 736.18 examples/s]\u001b[A\n",
      "Generating test examples...: 5439 examples [00:07, 730.52 examples/s]\u001b[A\n",
      "Generating test examples...: 5513 examples [00:07, 712.26 examples/s]\u001b[A\n",
      "Generating test examples...: 5585 examples [00:07, 700.10 examples/s]\u001b[A\n",
      "Generating test examples...: 5661 examples [00:08, 716.74 examples/s]\u001b[A\n",
      "Generating test examples...: 5734 examples [00:08, 720.07 examples/s]\u001b[A\n",
      "Generating test examples...: 5811 examples [00:08, 734.64 examples/s]\u001b[A\n",
      "Generating test examples...: 5890 examples [00:08, 748.87 examples/s]\u001b[A\n",
      "Generating test examples...: 5965 examples [00:08, 748.62 examples/s]\u001b[A\n",
      "Generating test examples...: 6045 examples [00:08, 763.42 examples/s]\u001b[A\n",
      "Generating test examples...: 6123 examples [00:08, 767.70 examples/s]\u001b[A\n",
      "Generating test examples...: 6201 examples [00:08, 766.89 examples/s]\u001b[A\n",
      "Generating test examples...: 6278 examples [00:08, 765.15 examples/s]\u001b[A\n",
      "Generating test examples...: 6355 examples [00:09, 719.22 examples/s]\u001b[A\n",
      "Generating test examples...: 6428 examples [00:09, 706.16 examples/s]\u001b[A\n",
      "Generating test examples...: 6502 examples [00:09, 713.93 examples/s]\u001b[A\n",
      "Generating test examples...: 6580 examples [00:09, 730.71 examples/s]\u001b[A\n",
      "Generating test examples...: 6659 examples [00:09, 747.67 examples/s]\u001b[A\n",
      "Generating test examples...: 6737 examples [00:09, 752.63 examples/s]\u001b[A\n",
      "Generating test examples...: 6816 examples [00:09, 760.55 examples/s]\u001b[A\n",
      "Generating test examples...: 6894 examples [00:09, 764.74 examples/s]\u001b[A\n",
      "Generating test examples...: 6971 examples [00:09, 740.32 examples/s]\u001b[A\n",
      "Generating test examples...: 7046 examples [00:09, 729.46 examples/s]\u001b[A\n",
      "Generating test examples...: 7120 examples [00:10, 724.25 examples/s]\u001b[A\n",
      "Generating test examples...: 7197 examples [00:10, 735.39 examples/s]\u001b[A\n",
      "Generating test examples...: 7274 examples [00:10, 744.07 examples/s]\u001b[A\n",
      "Generating test examples...: 7352 examples [00:10, 754.57 examples/s]\u001b[A\n",
      "Generating test examples...: 7428 examples [00:10, 734.39 examples/s]\u001b[A\n",
      "Generating test examples...: 7502 examples [00:10, 716.58 examples/s]\u001b[A\n",
      "Generating test examples...: 7580 examples [00:10, 733.60 examples/s]\u001b[A\n",
      "Generating test examples...: 7656 examples [00:10, 740.67 examples/s]\u001b[A\n",
      "Generating test examples...: 7731 examples [00:10, 730.32 examples/s]\u001b[A\n",
      "Generating test examples...: 7805 examples [00:10, 687.47 examples/s]\u001b[A\n",
      "Generating test examples...: 7875 examples [00:11, 690.77 examples/s]\u001b[A\n",
      "Generating test examples...: 7945 examples [00:11, 662.14 examples/s]\u001b[A\n",
      "Generating test examples...: 8025 examples [00:11, 700.81 examples/s]\u001b[A\n",
      "Generating test examples...: 8096 examples [00:11, 694.32 examples/s]\u001b[A\n",
      "Generating test examples...: 8171 examples [00:11, 708.83 examples/s]\u001b[A\n",
      "Generating test examples...: 8243 examples [00:11, 710.67 examples/s]\u001b[A\n",
      "Generating test examples...: 8316 examples [00:11, 714.49 examples/s]\u001b[A\n",
      "Generating test examples...: 8391 examples [00:11, 723.37 examples/s]\u001b[A\n",
      "Generating test examples...: 8466 examples [00:11, 730.37 examples/s]\u001b[A\n",
      "Generating test examples...: 8540 examples [00:12, 717.17 examples/s]\u001b[A\n",
      "Generating test examples...: 8619 examples [00:12, 737.26 examples/s]\u001b[A\n",
      "Generating test examples...: 8693 examples [00:12, 712.85 examples/s]\u001b[A\n",
      "Generating test examples...: 8766 examples [00:12, 715.80 examples/s]\u001b[A\n",
      "Generating test examples...: 8844 examples [00:12, 733.42 examples/s]\u001b[A\n",
      "Generating test examples...: 8919 examples [00:12, 737.20 examples/s]\u001b[A\n",
      "Generating test examples...: 8993 examples [00:12, 718.75 examples/s]\u001b[A\n",
      "Generating test examples...: 9075 examples [00:12, 741.48 examples/s]\u001b[A\n",
      "Generating test examples...: 9152 examples [00:12, 747.68 examples/s]\u001b[A\n",
      "Generating test examples...: 9227 examples [00:12, 702.78 examples/s]\u001b[A\n",
      "Generating test examples...: 9298 examples [00:13, 699.70 examples/s]\u001b[A\n",
      "Generating test examples...: 9369 examples [00:13, 700.19 examples/s]\u001b[A\n",
      "Generating test examples...: 9440 examples [00:13, 673.66 examples/s]\u001b[A\n",
      "Generating test examples...: 9508 examples [00:13, 656.91 examples/s]\u001b[A\n",
      "Generating test examples...: 9584 examples [00:13, 683.04 examples/s]\u001b[A\n",
      "Generating test examples...: 9660 examples [00:13, 702.50 examples/s]\u001b[A\n",
      "Generating test examples...: 9738 examples [00:13, 723.60 examples/s]\u001b[A\n",
      "Generating test examples...: 9820 examples [00:13, 749.63 examples/s]\u001b[A\n",
      "Generating test examples...: 9896 examples [00:13, 742.91 examples/s]\u001b[A\n",
      "Generating test examples...: 9972 examples [00:14, 745.73 examples/s]\u001b[A\n",
      "                                                                     \u001b[A\n",
      "Shuffling cifar10-test.tfrecord...:   0%|          | 0/10000 [00:00<?, ? examples/s]\u001b[A\n",
      "Shuffling cifar10-test.tfrecord...:  34%|███▎      | 3368/10000 [00:00<00:00, 33563.36 examples/s]\u001b[A\n",
      "Shuffling cifar10-test.tfrecord...:  77%|███████▋  | 7680/10000 [00:00<00:00, 38948.41 examples/s]\u001b[A\n",
      "\u001b[1mDataset cifar10 downloaded and prepared to .data/cifar10\\3.0.2. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "CIFAR10.update({\n",
    "    \"train\": atk.dataset.get_np_data(\n",
    "        name=\"cifar10\",\n",
    "        split=\"train[:64]\",\n",
    "        flatten=False,\n",
    "        data_dir=\".data/\"),\n",
    "    \"test\": atk.dataset.get_np_data(\n",
    "        name=\"cifar10\",\n",
    "        split=\"test[:256]\",\n",
    "        flatten=False,\n",
    "        data_dir=\".data/\"),\n",
    "    \"dataset\": robustness.datasets.CIFAR(\".data\"),\n",
    "    \"workers\": 12,\n",
    "    \"arch\": \"resnet50\",\n",
    "    \"resume_path_nat\": \".models/cifar_nat.pt\",\n",
    "    \"resume_path_linf\": \".models/cifar_linf_8.pt\",\n",
    "    \"labels\": [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n",
    "        \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"],\n",
    "    \n",
    "    \"batch_size\": 256,\n",
    "    \"perturb_eps\": 8/255,\n",
    "\n",
    "    \"display_samples\": 10,\n",
    "    \"display_sample_img_size\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=> loading checkpoint '.models/cifar_nat.pt'\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-e0eb90fec164>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         dataset=exp[\"dataset\"])\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mexp_load_saved\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCIFAR10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-e0eb90fec164>\u001b[0m in \u001b[0;36mexp_load_saved\u001b[1;34m(exp)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mexp_load_saved\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     exp[\"model_nat\"], _ = model_utils.make_and_restore_model(\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[0march\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"arch\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mresume_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"resume_path_nat\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         dataset=exp[\"dataset\"])\n",
      "\u001b[1;32mc:\\users\\0\\main\\active\\monochrome\\adversarial-ntks\\robustness\\robustness\\model_utils.py\u001b[0m in \u001b[0;36mmake_and_restore_model\u001b[1;34m(arch, dataset, resume_path, parallel, pytorch_pretrained, add_custom_forward, *_)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mresume_path\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresume_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"=> loading checkpoint '{}'\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresume_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[0mcheckpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresume_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdill\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;31m# Makes us able to load models saved with legacy versions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\0\\main\\active\\monochrome\\adversarial-ntks\\.venv\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    591\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\0\\main\\active\\monochrome\\adversarial-ntks\\.venv\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    770\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    771\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 772\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    773\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    774\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\0\\main\\active\\monochrome\\adversarial-ntks\\.venv\\lib\\site-packages\\dill\\_dill.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    480\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#NOTE: if settings change, need to update attributes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 481\u001b[1;33m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStockUnpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    482\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_main_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__name__'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    483\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ignore\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\0\\main\\active\\monochrome\\adversarial-ntks\\.venv\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m    726\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_torch_load_uninitialized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m                 \u001b[0mdeserialized_objects\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    729\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mview_metadata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\0\\main\\active\\monochrome\\adversarial-ntks\\.venv\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\0\\main\\active\\monochrome\\adversarial-ntks\\.venv\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[1;34m(obj, location)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_cuda_deserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m         \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_cuda_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_torch_load_uninitialized\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m             \u001b[0mstorage_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\0\\main\\active\\monochrome\\adversarial-ntks\\.venv\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mvalidate_cuda_device\u001b[1;34m(location)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m         raise RuntimeError('Attempting to deserialize object on a CUDA '\n\u001b[0m\u001b[0;32m    136\u001b[0m                            \u001b[1;34m'device but torch.cuda.is_available() is False. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                            \u001b[1;34m'If you are running on a CPU-only machine, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "def exp_load_saved(exp):\n",
    "    exp[\"model_nat\"], _ = model_utils.make_and_restore_model(\n",
    "        arch=exp[\"arch\"],\n",
    "        resume_path=exp[\"resume_path_nat\"],\n",
    "        dataset=exp[\"dataset\"])\n",
    "    exp[\"model_linf\"], _ = model_utils.make_and_restore_model(\n",
    "        arch=exp[\"arch\"],\n",
    "        resume_path=exp[\"resume_path_linf\"],\n",
    "        dataset=exp[\"dataset\"])\n",
    "\n",
    "exp_load_saved(CIFAR10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_load_saved(exp):\n",
    "    exp[\"model_nat\"], _ = model_utils.make_and_restore_model(\n",
    "        arch=exp[\"arch\"],\n",
    "        resume_path=exp[\"resume_path_nat\"],\n",
    "        dataset=exp[\"dataset\"])\n",
    "    exp[\"model_linf\"], _ = model_utils.make_and_restore_model(\n",
    "        arch=exp[\"arch\"],\n",
    "        resume_path=exp[\"resume_path_linf\"],\n",
    "        dataset=exp[\"dataset\"])\n",
    "\n",
    "exp_load_saved(CIFAR10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def exp_eval_ueb_atk(exp, models, dss, samples):\n",
    "    c_correct = {}\n",
    "    for ds in dss:\n",
    "        xs_gpu = torch.Tensor(np.transpose(exp[ds].xs, (0, 3, 1, 2))).cuda()\n",
    "        ys_gpu = torch.Tensor(exp[ds].ys).cuda()\n",
    "        c_batches = len(exp[ds].xs) // exp[\"batch_size\"]\n",
    "\n",
    "        c_correct[ds] = {}\n",
    "        for model in models:\n",
    "            c_correct[ds][model] = []\n",
    "    \n",
    "        for batch_id in tqdm.notebook.tqdm(range(c_batches), desc=\"Batch\"):\n",
    "            batch_start = batch_id * exp[\"batch_size\"]\n",
    "            batch_end = batch_start + exp[\"batch_size\"]\n",
    "            batch_xs = xs_gpu[batch_start:batch_end]\n",
    "            batch_ys = ys_gpu[batch_start:batch_end]\n",
    "\n",
    "            c_correct_batch = {}\n",
    "            for model in models:\n",
    "                c_correct_batch[model] = []\n",
    "\n",
    "            for sample in tqdm.notebook.tqdm(range(samples), desc=\"Sample\"):\n",
    "                xs_perturbation = (torch.rand(batch_xs.shape) * \\\n",
    "                    exp[\"perturb_eps\"] * 2 - exp[\"perturb_eps\"]).cuda()\n",
    "                xs_perturbed = batch_xs.add(xs_perturbation).clamp(0, 1)\n",
    "\n",
    "                for model in models:\n",
    "                    predictions = exp[model](xs_perturbed)[0].argmax(dim=1)\n",
    "                    c_correct_batch[model].append(\n",
    "                        predictions.eq(batch_ys).cpu())\n",
    "                        \n",
    "                    del predictions\n",
    "\n",
    "                del xs_perturbation, xs_perturbed\n",
    "\n",
    "            for model in models:\n",
    "                c_correct[ds][model].append(np.vstack(\n",
    "                    c_correct_batch[model]).transpose())\n",
    "\n",
    "        for model in models:\n",
    "            c_correct[ds][model] = \\\n",
    "                np.concatenate(c_correct[ds][model]).astype(int)\n",
    "\n",
    "        del xs_gpu, ys_gpu\n",
    "    \n",
    "    return c_correct\n",
    "\n",
    "CIFAR10[\"ueb-atk-res\"] = exp_eval_ueb_atk(\n",
    "    CIFAR10,\n",
    "    [\"model_nat\", \"model_linf\"],\n",
    "    [\"test\"],\n",
    "    512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_show_ueb_atk_res(exp):\n",
    "    res = CIFAR10[\"ueb-atk-res\"]\n",
    "    dss, models = [], []\n",
    "    for ds in res.keys():\n",
    "        dss.append(ds)\n",
    "        if len(models) == 0:\n",
    "            for model in res[ds].keys():\n",
    "                models.append(model)\n",
    "\n",
    "    print(dss, models)\n",
    "    fig, ax = plt.subplots(len(dss), len(models), figsize=(5 * len(models), 5 * len(dss)))\n",
    "    fig2, ax2 = plt.subplots(1, len(dss), figsize=(5 * len(dss), 5))\n",
    "    fig3, ax3 = plt.subplots(1, len(dss), figsize=(5 * len(dss), 5))\n",
    "\n",
    "    for ds_i in range(len(dss)):\n",
    "        ds = dss[ds_i]\n",
    "        for model_i in range(len(models)):\n",
    "            model = models[model_i]\n",
    "            cur_ax = ax if type(ax) is not np.ndarray else (\n",
    "                ax[model_i] if type(ax[model_i]) is not np.ndarray else\n",
    "                    ax[ds_i][model_i])\n",
    "            uebp = 1 - \\\n",
    "                np.sum(res[ds][model], axis=1) / res[ds][model].shape[1]\n",
    "            cur_ax.hist(uebp, bins=64, range=(0, 1))\n",
    "            cur_ax.set_title(ds + \" // \" + model + \" // {:.4f}\".format(\n",
    "                np.count_nonzero(1 - res[ds][model].mean(axis=1)) /\n",
    "                res[ds][model].shape[0]))\n",
    "            cur_ax.set_xlabel(\"% of adversarial samples\")\n",
    "            cur_ax.set_ylabel(\"Number of points\")\n",
    "\n",
    "        if len(models) == 2:\n",
    "            cur_ax = ax2 if type(ax2) is not np.ndarray else ax2[ds_i]\n",
    "            res1, res2 = res[ds][models[0]], res[ds][models[1]]\n",
    "            eval_equal = res1 == res2\n",
    "            overlap = np.sum(eval_equal, axis=1) / res1.shape[1]\n",
    "            cur_ax.hist(overlap, bins=64, range=(0, 1))\n",
    "            cur_ax.set_title(ds + \" // {:.4f}\".format(overlap.mean()))\n",
    "            cur_ax.set_xlabel(\"% of equally adversarial samples b/t models\")\n",
    "            cur_ax.set_ylabel(\"Number of points\")\n",
    "\n",
    "            cur_ax = ax3 if type(ax3) is not np.ndarray else ax3[ds_i]\n",
    "            res_means = 1 - res1.mean(axis=1), 1 - res2.mean(axis=1)\n",
    "            cur_ax.scatter(*res_means)\n",
    "            cur_ax.set_title(ds)\n",
    "            cur_ax.set_xlabel(models[0] + \" uebp\")\n",
    "            cur_ax.set_ylabel(models[1] + \" uebp\")\n",
    "            cur_ax.set_xlim(-0.1, 1.1)\n",
    "            cur_ax.set_ylim(-0.1, 1.1)\n",
    "\n",
    "    fig.show()\n",
    "    fig2.show()\n",
    "    fig3.show()\n",
    "\n",
    "exp_show_ueb_atk_res(CIFAR10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}