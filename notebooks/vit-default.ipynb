{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "labeled-blowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import functools\n",
    "import copy\n",
    "import sys\n",
    "import pickle\n",
    "import tarfile\n",
    "import operator\n",
    "import math\n",
    "import requests\n",
    "import importlib\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "import scipy\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import flax\n",
    "\n",
    "import neural_tangents as nt\n",
    "\n",
    "import vit_jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "natural-matrix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 32, 32, 3)\n",
      "(1, 256, 10)\n"
     ]
    }
   ],
   "source": [
    "# Helper functions for images.\n",
    "labelnames = dict(\n",
    "    # https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "    cifar10=('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'),\n",
    "    # https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "    cifar100=('apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'computer_keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm')\n",
    ")\n",
    "def make_label_getter(dataset):\n",
    "    \"\"\"Returns a function converting label indices to names.\"\"\"\n",
    "    def getter(label):\n",
    "        if dataset in labelnames:\n",
    "            return labelnames[dataset][label]\n",
    "        return f'label={label}'\n",
    "    return getter\n",
    "\n",
    "def show_img(img, ax=None, title=None):\n",
    "  \"\"\"Shows a single image.\"\"\"\n",
    "  if ax is None:\n",
    "    ax = plt.gca()\n",
    "  ax.imshow(img[...])\n",
    "  ax.set_xticks([])\n",
    "  ax.set_yticks([])\n",
    "  if title:\n",
    "    ax.set_title(title)\n",
    "\n",
    "def show_img_grid(imgs, titles):\n",
    "  \"\"\"Shows a grid of images.\"\"\"\n",
    "  n = int(np.ceil(len(imgs)**.5))\n",
    "  _, axs = plt.subplots(n, n, figsize=(3 * n, 3 * n))\n",
    "  for i, (img, title) in enumerate(zip(imgs, titles)):\n",
    "    img = (img + 1) / 2  # Denormalize\n",
    "    show_img(img, axs[i // n][i % n], title)\n",
    "\n",
    "dataset = 'cifar10'\n",
    "batch_size = 256  # Reduce to 256 if running on a single GPU.\n",
    "\n",
    "# Note the datasets are configured in input_pipeline.DATASET_PRESETS\n",
    "# Have a look in the editor at the right.\n",
    "num_classes = vit_jax.input_pipeline.get_dataset_info(dataset, 'train')['num_classes']\n",
    "# tf.data.Datset for training, infinite repeats.\n",
    "ds_train = vit_jax.input_pipeline.get_data(\n",
    "    dataset=dataset, mode='train', repeats=None, batch_size=batch_size,\n",
    "    tfds_data_dir=\".data/\"\n",
    ")\n",
    "# tf.data.Datset for evaluation, single repeat.\n",
    "ds_test = vit_jax.input_pipeline.get_data(\n",
    "    dataset=dataset, mode='test', repeats=None, batch_size=batch_size,\n",
    "    tfds_data_dir=\".data/\"\n",
    ")\n",
    "\n",
    "# Fetch a batch of test images for illustration purposes.\n",
    "batch = next(iter(ds_test.as_numpy_iterator()))\n",
    "# Note the shape : [num_local_devices, local_batch_size, h, w, c]\n",
    "print(batch['image'].shape)\n",
    "print(batch[\"label\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fossil-vietnamese",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 23:41:27,573 [WARNING] vit_jax.logging: Inspect recovered empty keys:\n",
      "{'pre_logits'}\n",
      "2021-01-26 23:41:27,576 [INFO] vit_jax.logging: Inspect extra keys:\n",
      "{'pre_logits/bias', 'pre_logits/kernel'}\n",
      "2021-01-26 23:41:27,578 [INFO] vit_jax.logging: load_pretrained: drop-head variant\n",
      "2021-01-26 23:41:27,580 [INFO] vit_jax.logging: load_pretrained: resized variant: (1, 197, 768) to (1, 5, 768)\n",
      "2021-01-26 23:41:27,582 [INFO] vit_jax.logging: load_pretrained: grid-size from 14 to 2\n",
      "2021-01-26 23:41:28,132 [INFO] absl: Load pre-computed DatasetInfo (eg: splits, num examples,...) from GCS: cifar10/3.0.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params.cls: ndarray (1, 1, 768)\n",
      "params_repl.cls: ShardedDeviceArray (1, 1, 1, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 23:41:28,849 [INFO] absl: Load dataset info from /tmp/tmp3oeqy8b7tfds\n",
      "2021-01-26 23:41:28,851 [INFO] absl: Field info.citation from disk and from code do not match. Keeping the one from code.\n",
      "2021-01-26 23:41:28,852 [INFO] absl: Field info.splits from disk and from code do not match. Keeping the one from code.\n",
      "2021-01-26 23:41:28,853 [INFO] absl: Field info.module_name from disk and from code do not match. Keeping the one from code.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a083de86fd843c182b74d3ab56c4f15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray(0.09995994, dtype=float64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger = vit_jax.logging.setup_logger('.logs/')\n",
    "\n",
    "# Load model definition & initialize random parameters.\n",
    "VisionTransformer = vit_jax.models.KNOWN_MODELS[\"ViT-B_16\"].partial(num_classes=10)\n",
    "_, params = VisionTransformer.init_by_shape(\n",
    "    jax.random.PRNGKey(0),\n",
    "    # Discard the \"num_local_devices\" dimension of the batch for initialization.\n",
    "    [((batch_size, 32, 32, 3), 'float32')])\n",
    "\n",
    "# Load and convert pretrained checkpoint.\n",
    "# This involves loading the actual pre-trained model results, but then also also\n",
    "# modifying the parameters a bit, e.g. changing the final layers, and resizing\n",
    "# the positional embeddings.\n",
    "# For details, refer to the code and to the methods of the paper.\n",
    "params = vit_jax.checkpoint.load_pretrained(\n",
    "    pretrained_path='.models/ViT-B_16.npz',\n",
    "    init_params=params,\n",
    "    model_config=vit_jax.models.CONFIGS[\"ViT-B_16\"],\n",
    "    logger=logger\n",
    ")\n",
    "\n",
    "# So far, all our data is in the host memory. Let's now replicate the arrays\n",
    "# into the devices.\n",
    "# This will make every array in the pytree params become a ShardedDeviceArray\n",
    "# that has the same data replicated across all local devices.\n",
    "# For TPU it replicates the params in every core.\n",
    "# For a single GPU this simply moves the data onto the device.\n",
    "# For CPU it simply creates a copy.\n",
    "params_repl = flax.jax_utils.replicate(params)\n",
    "print('params.cls:', type(params['cls']).__name__, params['cls'].shape)\n",
    "print('params_repl.cls:', type(params_repl['cls']).__name__, params_repl['cls'].shape)\n",
    "\n",
    "# Then map the call to our model's forward pass onto all available devices.\n",
    "vit_apply_repl = jax.pmap(VisionTransformer.call)\n",
    "\n",
    "def get_accuracy(params_repl):\n",
    "  \"\"\"Returns accuracy evaluated on the test set.\"\"\"\n",
    "  good = total = 0\n",
    "  steps = vit_jax.input_pipeline.get_dataset_info(dataset, 'test')['num_examples'] // batch_size\n",
    "  for _, batch in zip(tqdm.notebook.trange(steps), ds_test.as_numpy_iterator()):\n",
    "    predicted = vit_apply_repl(params_repl, batch['image'])\n",
    "    is_same = predicted.argmax(axis=-1) == batch['label'].argmax(axis=-1)\n",
    "    good += is_same.sum()\n",
    "    total += len(is_same.flatten())\n",
    "  return good / total\n",
    "\n",
    "# Random performance without fine-tuning.\n",
    "get_accuracy(params_repl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "boolean-proxy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "206ba34fc86e43088b62d0a2361fa425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-27 00:05:36,010 [INFO] absl: Load pre-computed DatasetInfo (eg: splits, num examples,...) from GCS: cifar10/3.0.2\n",
      "2021-01-27 00:05:37,518 [INFO] absl: Load dataset info from /tmp/tmp6fe13xkwtfds\n",
      "2021-01-27 00:05:37,568 [INFO] absl: Field info.citation from disk and from code do not match. Keeping the one from code.\n",
      "2021-01-27 00:05:37,569 [INFO] absl: Field info.splits from disk and from code do not match. Keeping the one from code.\n",
      "2021-01-27 00:05:37,571 [INFO] absl: Field info.module_name from disk and from code do not match. Keeping the one from code.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f070e670ce49ef82eb28d615a9f836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray(0.44280849, dtype=float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 100 Steps take approximately 15 minutes in the TPU runtime.\n",
    "total_steps = 100\n",
    "warmup_steps = 5\n",
    "decay_type = 'cosine'\n",
    "grad_norm_clip = 1\n",
    "# This controls in how many forward passes the batch is split. 8 works well with\n",
    "# a TPU runtime that has 8 devices. 64 should work on a GPU. You can of course\n",
    "# also adjust the batch_size above, but that would require you to adjust the\n",
    "# learning rate accordingly.\n",
    "accum_steps = 64\n",
    "base_lr = 0.03\n",
    "\n",
    "# Check out train.make_update_fn in the editor on the right side for details.\n",
    "update_fn_repl = vit_jax.train.make_update_fn(VisionTransformer.call, accum_steps)\n",
    "# We use a momentum optimizer that uses half precision for state to save\n",
    "# memory. It als implements the gradient clipping.\n",
    "opt = vit_jax.momentum_clip.Optimizer(grad_norm_clip=grad_norm_clip).create(params)\n",
    "opt_repl = flax.jax_utils.replicate(opt)\n",
    "\n",
    "lr_fn = vit_jax.hyper.create_learning_rate_schedule(total_steps, base_lr, decay_type, warmup_steps)\n",
    "# Prefetch entire learning rate schedule onto devices. Otherwise we would have\n",
    "# a slow transfer from host to devices in every step.\n",
    "lr_iter = vit_jax.hyper.lr_prefetch_iter(lr_fn, 0, total_steps)\n",
    "# Initialize PRNGs for dropout.\n",
    "update_rngs = jax.random.split(jax.random.PRNGKey(0), jax.local_device_count())\n",
    "\n",
    "# The world's simplest training loop.\n",
    "# Completes in ~20 min on the TPU runtime.\n",
    "for step, batch, lr_repl in zip(\n",
    "    tqdm.notebook.trange(1, total_steps + 1),\n",
    "    ds_train.as_numpy_iterator(),\n",
    "    lr_iter\n",
    "):\n",
    "    opt_repl, loss_repl, update_rngs = update_fn_repl(\n",
    "        opt_repl, lr_repl, batch, update_rngs)\n",
    "\n",
    "# Should be ~97.2% for CIFAR10\n",
    "# Should be ~71.2% for CIFAR100\n",
    "get_accuracy(opt_repl.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-genre",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
