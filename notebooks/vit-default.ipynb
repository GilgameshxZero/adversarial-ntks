{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "labeled-blowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import functools\n",
    "import copy\n",
    "import sys\n",
    "import pickle\n",
    "import tarfile\n",
    "import operator\n",
    "import math\n",
    "import requests\n",
    "import importlib\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "import scipy\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import flax\n",
    "\n",
    "import neural_tangents as nt\n",
    "\n",
    "import vit_jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "natural-matrix",
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "\"Trying to access `splits['train']` but `splits` is empty. This likely indicate the dataset has not been generated yet.\"",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f6bb310dd792>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;31m# Note the datasets are configured in input_pipeline.DATASET_PRESETS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m# Have a look in the editor at the right.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvit_jax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_pipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dataset_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'num_classes'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;31m# tf.data.Datset for training, infinite repeats.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m ds_train = vit_jax.input_pipeline.get_data(\n",
      "\u001b[1;32mc:\\users\\0\\main\\active\\erlija\\adversarial-ntks\\vision_transformer\\vit_jax\\input_pipeline.py\u001b[0m in \u001b[0;36mget_dataset_info\u001b[1;34m(dataset, split)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_dataset_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m   \u001b[0mdata_builder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m   \u001b[0mnum_examples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_builder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplits\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_examples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m   \u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_builder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m   return {\n",
      "\u001b[1;32mc:\\Users\\0\\main\\active\\erlija\\adversarial-ntks\\.venv\\lib\\site-packages\\tensorflow_datasets\\core\\splits.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    219\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m       raise KeyError(\n\u001b[0m\u001b[0;32m    222\u001b[0m           \u001b[1;34mf\"Trying to access `splits[{key!r}]` but `splits` is empty. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m           \u001b[1;34m\"This likely indicate the dataset has not been generated yet.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Trying to access `splits['train']` but `splits` is empty. This likely indicate the dataset has not been generated yet.\""
     ]
    }
   ],
   "source": [
    "# Helper functions for images.\n",
    "labelnames = dict(\n",
    "    # https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "    cifar10=('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'),\n",
    "    # https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "    cifar100=('apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'computer_keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm')\n",
    ")\n",
    "def make_label_getter(dataset):\n",
    "    \"\"\"Returns a function converting label indices to names.\"\"\"\n",
    "    def getter(label):\n",
    "        if dataset in labelnames:\n",
    "            return labelnames[dataset][label]\n",
    "        return f'label={label}'\n",
    "    return getter\n",
    "\n",
    "def show_img(img, ax=None, title=None):\n",
    "  \"\"\"Shows a single image.\"\"\"\n",
    "  if ax is None:\n",
    "    ax = plt.gca()\n",
    "  ax.imshow(img[...])\n",
    "  ax.set_xticks([])\n",
    "  ax.set_yticks([])\n",
    "  if title:\n",
    "    ax.set_title(title)\n",
    "\n",
    "def show_img_grid(imgs, titles):\n",
    "  \"\"\"Shows a grid of images.\"\"\"\n",
    "  n = int(np.ceil(len(imgs)**.5))\n",
    "  _, axs = plt.subplots(n, n, figsize=(3 * n, 3 * n))\n",
    "  for i, (img, title) in enumerate(zip(imgs, titles)):\n",
    "    img = (img + 1) / 2  # Denormalize\n",
    "    show_img(img, axs[i // n][i % n], title)\n",
    "\n",
    "dataset = 'cifar10'\n",
    "batch_size = 256  # Reduce to 256 if running on a single GPU.\n",
    "\n",
    "# Note the datasets are configured in input_pipeline.DATASET_PRESETS\n",
    "# Have a look in the editor at the right.\n",
    "num_classes = vit_jax.input_pipeline.get_dataset_info(dataset, 'train')['num_classes']\n",
    "# tf.data.Datset for training, infinite repeats.\n",
    "ds_train = vit_jax.input_pipeline.get_data(\n",
    "    dataset=dataset, mode='train', repeats=None, batch_size=batch_size,\n",
    "    tfds_data_dir=\".data/\"\n",
    ")\n",
    "# tf.data.Datset for evaluation, single repeat.\n",
    "ds_test = vit_jax.input_pipeline.get_data(\n",
    "    dataset=dataset, mode='test', repeats=None, batch_size=batch_size,\n",
    "    tfds_data_dir=\".data/\"\n",
    ")\n",
    "\n",
    "# Fetch a batch of test images for illustration purposes.\n",
    "batch = next(iter(ds_test.as_numpy_iterator()))\n",
    "# Note the shape : [num_local_devices, local_batch_size, h, w, c]\n",
    "print(batch['image'].shape)\n",
    "print(batch[\"label\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = vit_jax.logging.setup_logger('.logs/')\n",
    "\n",
    "# Load model definition & initialize random parameters.\n",
    "VisionTransformer = vit_jax.models.KNOWN_MODELS[\"ViT-B_16\"].partial(num_classes=10)\n",
    "_, params = VisionTransformer.init_by_shape(\n",
    "    jax.random.PRNGKey(0),\n",
    "    # Discard the \"num_local_devices\" dimension of the batch for initialization.\n",
    "    [((batch_size, 32, 32, 3), 'float32')])\n",
    "\n",
    "# Load and convert pretrained checkpoint.\n",
    "# This involves loading the actual pre-trained model results, but then also also\n",
    "# modifying the parameters a bit, e.g. changing the final layers, and resizing\n",
    "# the positional embeddings.\n",
    "# For details, refer to the code and to the methods of the paper.\n",
    "params = vit_jax.checkpoint.load_pretrained(\n",
    "    pretrained_path='.models/ViT-B_16.npz',\n",
    "    init_params=params,\n",
    "    model_config=vit_jax.models.CONFIGS[\"ViT-B_16\"],\n",
    "    logger=logger\n",
    ")\n",
    "\n",
    "# So far, all our data is in the host memory. Let's now replicate the arrays\n",
    "# into the devices.\n",
    "# This will make every array in the pytree params become a ShardedDeviceArray\n",
    "# that has the same data replicated across all local devices.\n",
    "# For TPU it replicates the params in every core.\n",
    "# For a single GPU this simply moves the data onto the device.\n",
    "# For CPU it simply creates a copy.\n",
    "params_repl = flax.jax_utils.replicate(params)\n",
    "print('params.cls:', type(params['cls']).__name__, params['cls'].shape)\n",
    "print('params_repl.cls:', type(params_repl['cls']).__name__, params_repl['cls'].shape)\n",
    "\n",
    "# Then map the call to our model's forward pass onto all available devices.\n",
    "vit_apply_repl = jax.pmap(VisionTransformer.call)\n",
    "\n",
    "def get_accuracy(params_repl):\n",
    "  \"\"\"Returns accuracy evaluated on the test set.\"\"\"\n",
    "  good = total = 0\n",
    "  steps = vit_jax.input_pipeline.get_dataset_info(dataset, 'test')['num_examples'] // batch_size\n",
    "  for _, batch in zip(tqdm.notebook.trange(steps), ds_test.as_numpy_iterator()):\n",
    "    predicted = vit_apply_repl(params_repl, batch['image'])\n",
    "    is_same = predicted.argmax(axis=-1) == batch['label'].argmax(axis=-1)\n",
    "    good += is_same.sum()\n",
    "    total += len(is_same.flatten())\n",
    "  return good / total\n",
    "\n",
    "# Random performance without fine-tuning.\n",
    "get_accuracy(params_repl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 Steps take approximately 15 minutes in the TPU runtime.\n",
    "total_steps = 100\n",
    "warmup_steps = 5\n",
    "decay_type = 'cosine'\n",
    "grad_norm_clip = 1\n",
    "# This controls in how many forward passes the batch is split. 8 works well with\n",
    "# a TPU runtime that has 8 devices. 64 should work on a GPU. You can of course\n",
    "# also adjust the batch_size above, but that would require you to adjust the\n",
    "# learning rate accordingly.\n",
    "accum_steps = 64\n",
    "base_lr = 0.03\n",
    "\n",
    "# Check out train.make_update_fn in the editor on the right side for details.\n",
    "update_fn_repl = vit_jax.train.make_update_fn(VisionTransformer.call, accum_steps)\n",
    "# We use a momentum optimizer that uses half precision for state to save\n",
    "# memory. It als implements the gradient clipping.\n",
    "opt = vit_jax.momentum_clip.Optimizer(grad_norm_clip=grad_norm_clip).create(params)\n",
    "opt_repl = flax.jax_utils.replicate(opt)\n",
    "\n",
    "lr_fn = vit_jax.hyper.create_learning_rate_schedule(total_steps, base_lr, decay_type, warmup_steps)\n",
    "# Prefetch entire learning rate schedule onto devices. Otherwise we would have\n",
    "# a slow transfer from host to devices in every step.\n",
    "lr_iter = vit_jax.hyper.lr_prefetch_iter(lr_fn, 0, total_steps)\n",
    "# Initialize PRNGs for dropout.\n",
    "update_rngs = jax.random.split(jax.random.PRNGKey(0), jax.local_device_count())\n",
    "\n",
    "# The world's simplest training loop.\n",
    "# Completes in ~20 min on the TPU runtime.\n",
    "for step, batch, lr_repl in zip(\n",
    "    tqdm.notebook.trange(1, total_steps + 1),\n",
    "    ds_train.as_numpy_iterator(),\n",
    "    lr_iter\n",
    "):\n",
    "    opt_repl, loss_repl, update_rngs = update_fn_repl(\n",
    "        opt_repl, lr_repl, batch, update_rngs)\n",
    "\n",
    "# Should be ~97.2% for CIFAR10\n",
    "# Should be ~71.2% for CIFAR100\n",
    "get_accuracy(opt_repl.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-genre",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}